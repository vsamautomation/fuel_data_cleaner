ğŸš€ Initializing Fabric Workspace Analyzer...

ğŸš€ STARTING COMPLETE FABRIC WORKSPACE ANALYSIS
================================================================================
ğŸ” STEP 1: Discovering workspaces...
  âœ… Found 4 workspaces

ğŸ” STEP 2: Getting datasets and reports...
  ğŸ“¦ Scanning workspace: Fabric_Demo
  ğŸ“¦ Scanning workspace: BI_Metadata
  ğŸ“¦ Scanning workspace: NLQ_Task
  ğŸ“¦ Scanning workspace: Auto_DP
  âœ… Found 8 datasets and 11 reports (7 PowerBI reports)

ğŸ” STEP 3: Processing all datasets and aggregating objects...
  ğŸ“Š Processing dataset: LH_D365FNO
    âš ï¸ Dependencies unavailable for LH_D365FNO: The database is empty. The DISCOVER_CALC_DEPENDENCY operation cannot be performed on an empty database.
    Found 0 expressions
  ğŸ“Š Processing dataset: NLQ_Model
    Found 1 expressions
    Found datsource for NLQ_Model
  ğŸ“Š Processing dataset: NLQ_Demo
    Found 1 expressions
    Found datsource for NLQ_Demo
  ğŸ“Š Processing dataset: IT Spend Analysis Sample PBIX
    Found 0 expressions
    Found datsource for IT Spend Analysis Sample PBIX
  ğŸ“Š Processing dataset: COVID Bakeoff
    Found 8 expressions
    Found datsource for COVID Bakeoff
  ğŸ“Š Processing dataset: Sales & Returns Sample v201912
    Found 0 expressions
    Found datsource for Sales & Returns Sample v201912
  ğŸ“Š Processing dataset: Sales & Returns Sample PBIX
    Found 0 expressions
    Found datsource for Sales & Returns Sample PBIX
  ğŸ“Š Processing dataset: COVID Bakeoff PBIR
    Found 8 expressions
    Found datsource for COVID Bakeoff PBIR
  âœ… Processed 8 datasets
    ğŸ“‹ Aggregated: 732 columns, 71 tables, 186 measures
    ğŸ”— Aggregated: 3148 dependencies, 58 relationships, 18 Expressions

ğŸ” STEP 4: Extracting report metadata...
  ğŸ“Š Processing report 1/8: NLQ
  ğŸ“‘ Report Type: PBIR-Legacy
    âœ… Extracted via JSON: 0 tables, 0 columns, 0 measures
  ğŸ“Š Processing report 2/8: NLQ_Demo
  ğŸ“‘ Report Type: PBIR-Legacy
    âœ… Extracted via JSON: 2 tables, 4 columns, 1 measures
  ğŸ“Š Processing report 3/8: IT Spend Analysis Sample PBIX
  ğŸ“‘ Report Type: PBIR-Legacy
    âœ… Extracted via JSON: 8 tables, 11 columns, 5 measures
  ğŸ“Š Processing report 4/8: COVID Bakeoff
  ğŸ“‘ Report Type: PBIR-Legacy
    âœ… Extracted via JSON: 11 tables, 24 columns, 15 measures
  ğŸ“Š Processing report 5/8: Sales & Returns Sample v201912
  ğŸ“‘ Report Type: PBIR
    âœ… Extracted via sempy_labs: 14 tables, 42 columns, 24 measures
  ğŸ“Š Processing report 6/8: Sales & Returns Sample PBIX
  ğŸ“‘ Report Type: PBIR-Legacy
    âœ… Extracted via JSON: 22 tables, 37 columns, 21 measures
  ğŸ“Š Processing report 7/8: COVID Bakeoff PBIR
  ğŸ“‘ Report Type: PBIR-Legacy
  âœ… Saved 918 records to 'ai_object_features' table
     ğŸ“ AI-ready object-level features with full lineage context for predictions

ğŸ”— Saving relationships table...
  âœ… Saved 58 records to 'dataset_relationships' table
     ğŸ“ All relationships across datasets with qualified column references

ğŸ”— Saving dependencies table...
  âœ… Saved 3148 records to 'dataste_dependencies' table
     ğŸ“ All dataset dependedncies for reference later

ğŸ“ Saving expressions table...
  âœ… Saved 18 records to 'dataset_expressions' table
     ğŸ“ M code expressions from Power Query for all datasets

âœ… AI-optimized lakehouse tables created successfully!
   ğŸ“Š ai_dataset_context: 8 datasets with 16 features
   ğŸ“Š ai_object_features: 918 objects (columns + measures) with 23 features

ğŸ’¡ Use these tables for:
   - Training schema optimization models
   - Predicting unused objects
   - Generating dataset health scores
   - Recommending model improvements

================================================================================
ğŸ‰ FABRIC WORKSPACE ANALYSIS COMPLETE!
================================================================================
â±ï¸ Total execution time: 233.94 seconds

ğŸ“Š Summary:
  Workspaces analyzed: 4
  Datasets processed: 8
  Reports analyzed: 7
  Total objects found: 732 columns, 71 tables, 186 measures
  Used objects: 237 columns, 54 tables, 102 measures
  Unused objects: 495 columns, 17 tables, 84 measures

ğŸ’¾ All results saved to lakehouse tables!
================================================================================

ğŸ‰ Analysis complete! AI-optimized tables are ready.

ğŸ“Š Quick Access:
  ai_datasets = spark.table('ai_dataset_context').toPandas()
  ai_objects = spark.table('ai_object_features').toPandas()
/opt/spark/python/lib/pyspark.zip/pyspark/sql/pandas/conversion.py:351: UserWarning: createDataFrame attempted Arrow optimization because 'spark.sql.execution.arrow.pyspark.enabled' is set to true; however, failed by the reason below:
  Could not convert Series([], Name: datasource, dtype: object) with type Series: did not recognize Python value type when inferring an Arrow data type
Attempting non-optimization as 'spark.sql.execution.arrow.pyspark.fallback.enabled' is set to true.