{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e77bf5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "from io import StringIO\n",
    "from datetime import datetime\n",
    "import argparse\n",
    "import os\n",
    "from site_identifier import identify_sites"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 57,
=======
   "execution_count": 5,
   "id": "d1527bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "GOOGLE_SHEET_URL = \"https://docs.google.com/spreadsheets/d/e/2PACX-1vRpva-TXUaQR_6tJoXX2vnSN2ertC5GNxAgssqmXvIhqHBNrscDxSxtiSWbCiiHqAoSHb3SzXDQw_VX/pub?gid=1048590026&single=true&output=csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
>>>>>>> 87e965b46c39f97ad5410632916b1d336604ff04
   "id": "d3b2c8f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data from Google Sheets...\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Fetch Google Sheets data\"\"\"\n",
    "print(\"Fetching data from Google Sheets...\")\n",
    "response = requests.get(GOOGLE_SHEETS_URL_2, timeout=30)\n",
    "response.raise_for_status()\n",
    "df = pd.read_csv(StringIO(response.text), header=None, low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 58,
   "id": "60b830c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
=======
   "execution_count": 7,
>>>>>>> 87e965b46c39f97ad5410632916b1d336604ff04
   "id": "097e31f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identifying sites dynamically...\n",
      "Strategy: Finding 'INV. SETTING' labels and extracting site names\n",
      "\n",
      "  ✓ Row 4: Chukchansi | Coarsegold\n",
      "  ✓ Row 51: Yokut | OLD Lemoore\n",
      "  ✓ Row 99: Yokut 2\n",
      "  ✓ Row 142: Coyote Valley | Redwood\n",
      "  ✓ Row 177: Robinson | Pomo Pumps\n",
      "  ✓ Row 212: Diamond Mt. | Susanville\n",
      "  ✓ Row 247: Feather / Falls Upper\n",
      "  ✓ Row 282: Feather Falls | Lower\n",
      "  ✓ Row 329: Berry Creek | Maidu Mart\n",
      "  ✓ Row 372: Hidden Oaks | Covelo\n",
      "  ✓ Row 407: Pit River | Tamarack\n",
      "  ✓ Row 442: Chimney Rock | Alturas\n",
      "  ✓ Row 477: Shingle Springs | Express\n",
      "  ✓ Row 512: Cedarville | Rabbit Traxx\n",
      "  ✓ Row 548: Bear Creek | Tuolumne\n",
      "  ✓ Row 591: Middletown | Uncle Buddies\n",
      "  ✓ Row 626: Rolling Hills | Paskenta\n",
      "  ✓ Row 661: Colusa\n",
      "  ✓ Row 704: Enterprise | Hard Rock\n",
      "  ✓ Row 739: Buena Vista\n",
      "  ✓ Row 775: Big Valley\n",
      "  ✓ Row 826: Jackson Rancheria\n",
      "\n",
      "✓ Total sites identified: 22\n"
     ]
    }
   ],
   "source": [
    "sites = identify_sites(df)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 21,
   "id": "e935cba3",
=======
   "execution_count": 8,
   "id": "024480f6",
>>>>>>> 87e965b46c39f97ad5410632916b1d336604ff04
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_dates(df, start_col=6):\n",
    "    \"\"\"Extract all date columns from the sheet (up to today only)\"\"\"\n",
    "    print(\"\\nExtracting all dates...\")\n",
    "    dates_row = df.iloc[0, start_col:]\n",
    "    \n",
    "    today = pd.Timestamp.now().normalize()  # Get today's date at midnight\n",
    "    \n",
    "    date_data = []\n",
    "    for col_idx, date_val in enumerate(dates_row, start=start_col):\n",
    "        if pd.notna(date_val):\n",
    "            try:\n",
    "                parsed = pd.to_datetime(str(date_val), format='%b-%d-%y', errors='coerce')\n",
    "                if parsed and parsed <= today:  # Only include dates up to today\n",
    "                    date_data.append((col_idx, parsed))\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "    print(f\"✓ Found {len(date_data)} dates (up to today)\")\n",
    "    if date_data:\n",
    "        print(f\"  Date range: {date_data[0][1].date()} to {date_data[-1][1].date()}\")\n",
    "    return date_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 22,
   "id": "d2d2f2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_site_readings(df, site_row, site_name, date_columns):\n",
    "    \"\"\"Extract readings for a single site\"\"\"\n",
    "    print(f\"  Extracting READINGS for {site_name}...\")\n",
    "    \n",
    "    # Find READINGS section\n",
    "    reading_start_row = None\n",
    "    reading_end_row = None\n",
    "    \n",
    "    for offset in range(20):\n",
    "        row_idx = site_row + offset\n",
    "        if row_idx >= len(df):\n",
    "            break\n",
    "        \n",
    "        section_label = str(df.iloc[row_idx, 3]).strip() if pd.notna(df.iloc[row_idx, 3]) else \"\"\n",
    "        \n",
    "        if \"READINGS\" in section_label.upper():\n",
    "            reading_start_row = row_idx + 1\n",
    "            break\n",
    "    \n",
    "    if reading_start_row is None:\n",
    "        return []\n",
    "    \n",
    "    # Find end of READINGS section\n",
    "    for offset in range(15):\n",
    "        row_idx = reading_start_row + offset\n",
    "        if row_idx >= len(df):\n",
    "            break\n",
    "        \n",
    "        section_label = str(df.iloc[row_idx, 3]).strip() if pd.notna(df.iloc[row_idx, 3]) else \"\"\n",
    "        \n",
    "        if any(keyword in section_label.upper() for keyword in ['ULLAGE', 'LOADS', 'CARRIER', 'NOTES']):\n",
    "            reading_end_row = row_idx\n",
    "            break\n",
    "    \n",
    "    if reading_end_row is None:\n",
    "        reading_end_row = reading_start_row + 10\n",
    "    \n",
    "    # Scan READINGS section\n",
    "    records = []\n",
    "    products_found = {}\n",
    "    \n",
    "    for row_idx in range(reading_start_row, reading_end_row):\n",
    "        if row_idx >= len(df):\n",
    "            break\n",
    "        \n",
    "        product_cell = df.iloc[row_idx, 4]\n",
    "        \n",
    "        if pd.notna(product_cell):\n",
    "            product = str(product_cell).strip()\n",
    "            \n",
    "            if any(key in product for key in ['87', '88', '91', 'dsl', 'racing', 'red']):\n",
    "                if product not in products_found:\n",
    "                    products_found[product] = []\n",
    "                \n",
    "                products_found[product].append(row_idx)\n",
    "    \n",
    "    # Extract readings for each date\n",
    "    for col_idx, date in date_columns:\n",
    "        for product, row_indices in products_found.items():\n",
    "            record = {\n",
    "                'Date': date.strftime('%Y-%m-%d'),\n",
    "                'Site': site_name,\n",
    "                'Product': product\n",
    "            }\n",
    "            \n",
    "            for tank_num, row_idx in enumerate(row_indices, start=1):\n",
    "                value = df.iloc[row_idx, col_idx]\n",
    "                \n",
    "                if pd.notna(value):\n",
    "                    try:\n",
    "                        clean_val = str(value).replace(',', '').strip()\n",
    "                        numeric_val = float(clean_val) if clean_val else None\n",
    "                        record[f'Tank_{tank_num}_Reading'] = numeric_val\n",
    "                    except:\n",
    "                        record[f'Tank_{tank_num}_Reading'] = None\n",
    "                else:\n",
    "                    record[f'Tank_{tank_num}_Reading'] = None\n",
    "            \n",
    "            records.append(record)\n",
    "    \n",
    "    return records\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd864757",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_three_week_avg(df, site_row, site_name, all_dates):    \n",
    "    \"\"\"Get 3-week average sales for a site\"\"\"\n",
    "    print(f\" Getting 3-week average sales for {site_name}...\")\n",
    "    avg_start_row = None\n",
    "    product_name = None\n",
    "    avg_end_row = None\n",
    "    for offset in range(200):\n",
    "        row_idx = site_row + offset\n",
    "        if row_idx >= len(df):\n",
    "            break\n",
    "        \n",
    "        section_label = str(df.iloc[row_idx-1, 3]).strip() if pd.notna(df.iloc[row_idx-1, 3]) else \"\"\n",
    "        avg_col = str(df.iloc[row_idx, 4]).strip() if pd.notna(df.iloc[row_idx, 4]) else \"\"\n",
    "\n",
    "\n",
    "        if \"3 WK AVG\" in avg_col.upper():\n",
    "            avg_start_row = row_idx + 1\n",
    "            break\n",
    "    \n",
    "    if avg_start_row is None:\n",
    "        return []\n",
    "\n",
    "    # Find end of Avg Section\n",
    "    for offset in range(200):\n",
    "        row_idx = avg_start_row + offset\n",
    "        if row_idx >= len(df):\n",
    "            break\n",
    "        \n",
    "        section_label = str(df.iloc[row_idx, 3]).strip() if pd.notna(df.iloc[row_idx, 3]) else \"\"\n",
    "        \n",
    "        if any(keyword in section_label.upper() for keyword in ['ACTUAL']):\n",
    "            avg_end_row = row_idx\n",
    "            break\n",
    "    \n",
    "    if avg_end_row is None:\n",
    "        avg_end_row = avg_start_row + 100\n",
    "\n",
    "    records = []\n",
    "    products_found = {}\n",
    "\n",
    "    for row_idx in range(avg_start_row, avg_end_row):\n",
    "        if row_idx >= len(df):\n",
    "            break\n",
    "        \n",
    "        product_cell = df.iloc[row_idx-2, 4]\n",
    "        \n",
    "        if pd.notna(product_cell):\n",
    "            product = str(product_cell).strip()\n",
    "\n",
    "            if any(keyword in product for keyword in ['87', '88', '91', 'dsl', 'racing', 'red']):\n",
    "                if product not in products_found:\n",
    "                    products_found[product] = []\n",
    "                \n",
    "                products_found[product].append(row_idx)\n",
    "\n",
    "    for col_idx, date in all_dates:\n",
    "        for product, row_indices in products_found.items():\n",
    "            record = {\n",
    "                'Date': date.strftime('%Y-%m-%d'),\n",
    "                'Site': site_name,\n",
    "                'Product': product\n",
    "            }\n",
    "            for tank_num, row_idx in enumerate(row_indices, start=1):\n",
    "                value = df.iloc[row_idx-1, col_idx]\n",
    "                if pd.notna(value):\n",
    "                    try:\n",
    "                        clean_val = str(value).replace(',', '').strip()\n",
    "                        avg_val = float(clean_val) if clean_val else None\n",
    "                        record[f'Tank_{tank_num}_3_Week_Avg'] = avg_val\n",
    "                    except:\n",
    "                        record[f'Tank_{tank_num}_3_Week_Avg'] = None\n",
    "                else:\n",
    "                    record[f'Tank_{tank_num}_3_Week_Avg'] = None\n",
    "            \n",
    "            records.append(record)\n",
    "\n",
    "    return records\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "939890d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_2_month_avg(df, site_row, site_name, all_dates):    \n",
    "    \"\"\"Get 2-month average sales for a site\"\"\"\n",
    "    print(f\" Getting 2-month average sales for {site_name}...\")\n",
    "    avg_start_row = None\n",
    "    product_name = None\n",
    "    avg_end_row = None\n",
    "    for offset in range(200):\n",
    "        row_idx = site_row + offset\n",
    "        if row_idx >= len(df):\n",
    "            break\n",
    "        \n",
    "        section_label = str(df.iloc[row_idx-1, 3]).strip() if pd.notna(df.iloc[row_idx-1, 3]) else \"\"\n",
    "        avg_col = str(df.iloc[row_idx, 4]).strip() if pd.notna(df.iloc[row_idx, 4]) else \"\"\n",
    "\n",
    "\n",
    "        if \"2 MO AVG\" in avg_col.upper():\n",
    "            avg_start_row = row_idx + 1\n",
    "            break\n",
    "    \n",
    "    if avg_start_row is None:\n",
    "        return []\n",
    "\n",
    "    # Find end of Avg Section\n",
    "    for offset in range(200):\n",
    "        row_idx = avg_start_row + offset\n",
    "        if row_idx >= len(df):\n",
    "            break\n",
    "        \n",
    "        section_label = str(df.iloc[row_idx, 3]).strip() if pd.notna(df.iloc[row_idx, 3]) else \"\"\n",
    "        \n",
    "        if any(keyword in section_label.upper() for keyword in ['ACTUAL']):\n",
    "            avg_end_row = row_idx\n",
    "            break\n",
    "    \n",
    "    if avg_end_row is None:\n",
    "        avg_end_row = avg_start_row + 100\n",
    "\n",
    "    records = []\n",
    "    products_found = {}\n",
    "\n",
    "    for row_idx in range(avg_start_row, avg_end_row):\n",
    "        if row_idx >= len(df):\n",
    "            break\n",
    "        \n",
    "        product_cell = df.iloc[row_idx-3, 4]\n",
    "        \n",
    "        if pd.notna(product_cell):\n",
    "            product = str(product_cell).strip()\n",
    "            \n",
    "            if any(key in product for key in ['87', '88', '91', 'dsl', 'racing', 'red']):\n",
    "                if product not in products_found:\n",
    "                    products_found[product] = []\n",
    "                \n",
    "                products_found[product].append(row_idx)\n",
    "\n",
    "    for col_idx, date in all_dates:\n",
    "        for product, row_indices in products_found.items():\n",
    "            record = {\n",
    "                'Date': date.strftime('%Y-%m-%d'),\n",
    "                'Site': site_name,\n",
    "                'Product': product\n",
    "            }\n",
    "            for tank_num, row_idx in enumerate(row_indices, start=1):\n",
    "                value = df.iloc[row_idx-1, col_idx]\n",
    "                if pd.notna(value):\n",
    "                    try:\n",
    "                        clean_val = str(value).replace(',', '').strip()\n",
    "                        avg_val = float(clean_val) if clean_val else None\n",
    "                        record[f'Tank_{tank_num}_2_Month_Avg'] = avg_val\n",
    "                    except:\n",
    "                        record[f'Tank_{tank_num}_2_Month_Avg'] = None\n",
    "                else:\n",
    "                    record[f'Tank_{tank_num}_2_Month_Avg'] = None\n",
    "\n",
    "            records.append(record)\n",
    "\n",
    "    return records\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb255f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_site_loads(df, site_row, site_name, date_columns):\n",
    "    \"\"\"Extract loads (fuel deliveries) for a single site\"\"\"\n",
    "    print(f\"  Extracting LOADS for {site_name}...\")\n",
    "    \n",
    "    # First, find ULLAGE section\n",
    "    ullage_row = None\n",
    "    for offset in range(30):\n",
    "        row_idx = site_row + offset\n",
    "        if row_idx >= len(df):\n",
    "            break\n",
    "        \n",
    "        section_label = str(df.iloc[row_idx, 3]).strip() if pd.notna(df.iloc[row_idx, 3]) else \"\"\n",
    "        \n",
    "        if \"ULLAGE\" in section_label.upper():\n",
    "            ullage_row = row_idx\n",
    "            break\n",
    "    \n",
    "    if ullage_row is None:\n",
    "        return []\n",
    "    \n",
    "    # Now find LOADS section AFTER ullage\n",
    "    loads_start_row = None\n",
    "    loads_end_row = None\n",
    "    \n",
    "    for offset in range(1, 20):  # Start searching after ullage\n",
    "        row_idx = ullage_row + offset\n",
    "        if row_idx >= len(df):\n",
    "            break\n",
    "        \n",
    "        section_label = str(df.iloc[row_idx, 3]).strip() if pd.notna(df.iloc[row_idx, 3]) else \"\"\n",
    "        \n",
    "        if \"LOADS\" in section_label.upper():\n",
    "            loads_start_row = row_idx\n",
    "            break\n",
    "    \n",
    "    if loads_start_row is None:\n",
    "        return []\n",
    "    \n",
    "    # Find end of LOADS section\n",
    "    for offset in range(1, 15):\n",
    "        row_idx = loads_start_row + offset\n",
    "        if row_idx >= len(df):\n",
    "            break\n",
    "        \n",
    "        section_label = str(df.iloc[row_idx, 3]).strip() if pd.notna(df.iloc[row_idx, 3]) else \"\"\n",
    "        col1_label = str(df.iloc[row_idx, 1]).strip() if pd.notna(df.iloc[row_idx, 1]) else \"\"\n",
    "        \n",
    "        if any(keyword in section_label.upper() for keyword in ['SALES', 'CARRIER', 'NOTES']) or \\\n",
    "           any(keyword in col1_label.upper() for keyword in ['SALES', 'CARRIER']):\n",
    "            loads_end_row = row_idx\n",
    "            break\n",
    "    \n",
    "    if loads_end_row is None:\n",
    "        loads_end_row = loads_start_row + 10\n",
    "    \n",
    "    # Scan LOADS section - get product rows\n",
    "    records = []\n",
    "    products_found = {}\n",
    "    \n",
    "    for row_idx in range(loads_start_row, loads_end_row):\n",
    "        if row_idx >= len(df):\n",
    "            break\n",
    "        \n",
    "        product_cell = df.iloc[row_idx, 4]\n",
    "        \n",
    "        if pd.notna(product_cell):\n",
    "            product = str(product_cell).strip()\n",
    "            \n",
    "            # Get base product (87, 88, racing, red 91, dsl)\n",
    "            base_product = None\n",
    "            if any(keyword in product for keyword in ['87', '88', '91', 'dsl', 'racing', 'red']):\n",
    "                base_product = product\n",
    "            \n",
    "            # Capture all product rows (prefer total if exists, otherwise take the row)\n",
    "            if base_product:\n",
    "                is_total = \"total\" in product.lower()\n",
    "                # If we haven't seen this product yet, or this is a total row, store it\n",
    "                if base_product not in products_found or is_total:\n",
    "                    products_found[base_product] = row_idx\n",
    "    \n",
    "    # Extract loads for each date (only totals)\n",
    "    for col_idx, date in date_columns:\n",
    "        for product, row_idx in products_found.items():\n",
    "            value = df.iloc[row_idx, col_idx]\n",
    "            \n",
    "            if pd.notna(value):\n",
    "                try:\n",
    "                    clean_val = str(value).replace(',', '').strip()\n",
    "                    load_val = float(clean_val) if clean_val else None\n",
    "                    \n",
    "                    if load_val is not None:\n",
    "                        records.append({\n",
    "                            'Date': date.strftime('%Y-%m-%d'),\n",
    "                            'Site': site_name,\n",
    "                            'Product': product,\n",
    "                            'Load_Total': load_val\n",
    "                        })\n",
    "                except:\n",
    "                    pass\n",
    "    \n",
    "    return records\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "363c5d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_site_tank_sizes(df, site_row, site_name):\n",
    "    \"\"\"Extract tank sizes for a single site\"\"\"\n",
    "    print(f\"  Extracting TANK SIZES for {site_name}...\")\n",
    "    \n",
    "    # Find TANK SIZE label\n",
    "    tank_size_row = None\n",
    "    \n",
    "    for offset in range(40):\n",
    "        row_idx = site_row + offset\n",
    "        if row_idx >= len(df):\n",
    "            break\n",
    "        \n",
    "        label = str(df.iloc[row_idx, 1]).strip() if pd.notna(df.iloc[row_idx, 1]) else \"\"\n",
    "        \n",
    "        if \"TANK SIZE\" in label.upper():\n",
    "            tank_size_row = row_idx\n",
    "            break\n",
    "    \n",
    "    if tank_size_row is None:\n",
    "        return []\n",
    "    \n",
    "    # Extract tank sizes - first pass to collect all rows\n",
    "    records = []\n",
    "    products_data = {}  # {base_product: {'total': (row_idx, value), 'singles': [(row_idx, value), ...]}}\n",
    "    \n",
    "    for row_idx in range(tank_size_row + 1, tank_size_row + 20):\n",
    "        if row_idx >= len(df):\n",
    "            break\n",
    "        \n",
    "        col1_label = str(df.iloc[row_idx, 1]).strip() if pd.notna(df.iloc[row_idx, 1]) else \"\"\n",
    "        col3_label = str(df.iloc[row_idx, 3]).strip() if pd.notna(df.iloc[row_idx, 3]) else \"\"\n",
    "        \n",
    "        if \"SALES\" in col1_label.upper() or \"SALES\" in col3_label.upper():\n",
    "            break\n",
    "        \n",
    "        tank_size = df.iloc[row_idx, 1]\n",
    "        product_cell = df.iloc[row_idx, 4]\n",
    "        \n",
    "        if pd.notna(tank_size) and pd.notna(product_cell):\n",
    "            product = str(product_cell).strip()\n",
    "            \n",
    "            # Check if this product is relevant\n",
    "            if any(keyword in product for keyword in ['87', '88', '91', 'dsl', 'racing', 'red']):\n",
    "                is_total = \"total\" in product.lower()\n",
    "                # Get base product name (without \"total\")\n",
    "                base_product = product.lower().replace(\"total\", \"\").strip() if is_total else product\n",
    "                \n",
    "                try:\n",
    "                    clean_val = str(tank_size).replace(',', '').strip()\n",
    "                    size_val = float(clean_val) if clean_val else None\n",
    "                    \n",
    "                    if size_val and size_val > 0:\n",
    "                        if base_product not in products_data:\n",
    "                            products_data[base_product] = {'total': None, 'singles': []}\n",
    "                        \n",
    "                        if is_total:\n",
    "                            products_data[base_product]['total'] = (row_idx, size_val)\n",
    "                        else:\n",
    "                            products_data[base_product]['singles'].append((row_idx, size_val))\n",
    "                except:\n",
    "                    pass\n",
    "    \n",
    "    # Second pass: create records - use singles if they exist, otherwise use total\n",
    "    for base_product, data in products_data.items():\n",
    "        if data['singles']:  # If we have individual tanks, use those\n",
    "            for tank_num, (row_idx, size_val) in enumerate(data['singles'], start=1):\n",
    "                records.append({\n",
    "                    'Site': site_name,\n",
    "                    'Product': base_product,\n",
    "                    'Tank_Number': tank_num,\n",
    "                    'Tank_Size': size_val\n",
    "                })\n",
    "        elif data['total']:  # If we only have total, use that\n",
    "            row_idx, size_val = data['total']\n",
    "            records.append({\n",
    "                'Site': site_name,\n",
    "                'Product': base_product,\n",
    "                'Tank_Number': 1,\n",
    "                'Tank_Size': size_val\n",
    "            })\n",
    "    \n",
    "    return records\n",
    "\n",
    "    \"\"\"Extract tank sizes for a single site\"\"\"\n",
    "    print(f\"  Extracting TANK SIZES for {site_name}...\")\n",
    "    \n",
    "    # Find TANK SIZE label\n",
    "    tank_size_row = None\n",
    "    \n",
    "    for offset in range(40):\n",
    "        row_idx = site_row + offset\n",
    "        if row_idx >= len(df):\n",
    "            break\n",
    "        \n",
    "        label = str(df.iloc[row_idx, 1]).strip() if pd.notna(df.iloc[row_idx, 1]) else \"\"\n",
    "        \n",
    "        if \"TANK SIZE\" in label.upper():\n",
    "            tank_size_row = row_idx\n",
    "            break\n",
    "    \n",
    "    if tank_size_row is None:\n",
    "        return []\n",
    "    \n",
    "    # Extract tank sizes\n",
    "    records = []\n",
    "    products_found = {}\n",
    "    \n",
    "    for row_idx in range(tank_size_row + 1, tank_size_row + 20):\n",
    "        if row_idx >= len(df):\n",
    "            break\n",
    "        \n",
    "        col1_label = str(df.iloc[row_idx, 1]).strip() if pd.notna(df.iloc[row_idx, 1]) else \"\"\n",
    "        col3_label = str(df.iloc[row_idx, 3]).strip() if pd.notna(df.iloc[row_idx, 3]) else \"\"\n",
    "        \n",
    "        if \"SALES\" in col1_label.upper() or \"SALES\" in col3_label.upper():\n",
    "            break\n",
    "        \n",
    "        tank_size = df.iloc[row_idx, 1]\n",
    "        product_cell = df.iloc[row_idx, 4]\n",
    "        \n",
    "        if pd.notna(tank_size) and pd.notna(product_cell):\n",
    "            product = str(product_cell).strip()\n",
    "            \n",
    "            # Extract base product and strip \"total\" if present\n",
    "            base_product = None\n",
    "            if any(keyword in product for keyword in ['87', '88', '91', 'dsl', 'racing', 'red']):\n",
    "                # If \"total\" is in the product name, use the product without \"total\"\n",
    "                if \"total\" in product.lower():\n",
    "                    # Remove \"total\" and clean up extra spaces\n",
    "                    base_product = product.lower().replace(\"total\", \"\").strip()\n",
    "                else:\n",
    "                    base_product = product\n",
    "            \n",
    "            if base_product:\n",
    "                try:\n",
    "                    clean_val = str(tank_size).replace(',', '').strip()\n",
    "                    size_val = float(clean_val) if clean_val else None\n",
    "                    \n",
    "                    if size_val and size_val > 0:\n",
    "                        if base_product not in products_found:\n",
    "                            products_found[base_product] = []\n",
    "                        \n",
    "                        tank_num = len(products_found[base_product]) + 1\n",
    "                        products_found[base_product].append(size_val)\n",
    "                        \n",
    "                        records.append({\n",
    "                            'Site': site_name,\n",
    "                            'Product': base_product,\n",
    "                            'Tank_Number': tank_num,\n",
    "                            'Tank_Size': size_val\n",
    "                        })\n",
    "                except:\n",
    "                    pass\n",
    "    \n",
    "    return records\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ece32fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_site_inv_settings(df, site_row, site_name):\n",
    "    \"\"\"Extract inventory settings for a single site\"\"\"\n",
    "    print(f\"  Extracting INV SETTINGS for {site_name}...\")\n",
    "    \n",
    "    # Find INV SETTING label\n",
    "    inv_setting_row = None\n",
    "    \n",
    "    for offset in range(20):\n",
    "        row_idx = site_row + offset\n",
    "        if row_idx >= len(df):\n",
    "            break\n",
    "        \n",
    "        label = str(df.iloc[row_idx, 1]).strip() if pd.notna(df.iloc[row_idx, 1]) else \"\"\n",
    "        \n",
    "        if \"INV. SETTING\" in label.upper() or \"INV SETTING\" in label.upper():\n",
    "            inv_setting_row = row_idx\n",
    "            break\n",
    "    \n",
    "    if inv_setting_row is None:\n",
    "        return []\n",
    "    \n",
    "    # Extract inventory settings - first pass to collect all rows\n",
    "    records = []\n",
    "    products_data = {}  # {base_product: {'total': (row_idx, value), 'singles': [(row_idx, value), ...]}}\n",
    "    \n",
    "    for row_idx in range(inv_setting_row + 1, inv_setting_row + 20):\n",
    "        if row_idx >= len(df):\n",
    "            break\n",
    "        \n",
    "        col1_label = str(df.iloc[row_idx, 1]).strip() if pd.notna(df.iloc[row_idx, 1]) else \"\"\n",
    "        \n",
    "        if \"TANK SIZE\" in col1_label.upper():\n",
    "            break\n",
    "        \n",
    "        desired_level = df.iloc[row_idx, 1]\n",
    "        product_cell = df.iloc[row_idx, 4]\n",
    "        \n",
    "        if pd.notna(desired_level) and pd.notna(product_cell):\n",
    "            product = str(product_cell).strip()\n",
    "            \n",
    "            # Check if this product is relevant\n",
    "            if any(keyword in product for keyword in ['87', '88', '91', 'dsl', 'racing', 'red']):\n",
    "                is_total = \"total\" in product.lower()\n",
    "                # Get base product name (without \"total\")\n",
    "                base_product = product.lower().replace(\"total\", \"\").strip() if is_total else product\n",
    "                \n",
    "                try:\n",
    "                    clean_val = str(desired_level).replace(',', '').strip()\n",
    "                    level_val = float(clean_val) if clean_val else None\n",
    "                    \n",
    "                    if level_val and level_val > 0:\n",
    "                        if base_product not in products_data:\n",
    "                            products_data[base_product] = {'total': None, 'singles': []}\n",
    "                        \n",
    "                        if is_total:\n",
    "                            products_data[base_product]['total'] = (row_idx, level_val)\n",
    "                        else:\n",
    "                            products_data[base_product]['singles'].append((row_idx, level_val))\n",
    "                except:\n",
    "                    pass\n",
    "    \n",
    "    # Second pass: create records - use singles if they exist, otherwise use total\n",
    "    for base_product, data in products_data.items():\n",
    "        if data['singles']:  # If we have individual tanks, use those\n",
    "            for tank_num, (row_idx, level_val) in enumerate(data['singles'], start=1):\n",
    "                records.append({\n",
    "                    'Site': site_name,\n",
    "                    'Product': base_product,\n",
    "                    'Tank_Number': tank_num,\n",
    "                    'Desired_Level': level_val\n",
    "                })\n",
    "        elif data['total']:  # If we only have total, use that\n",
    "            row_idx, level_val = data['total']\n",
    "            records.append({\n",
    "                'Site': site_name,\n",
    "                'Product': base_product,\n",
    "                'Tank_Number': 1,\n",
    "                'Desired_Level': level_val\n",
    "            })\n",
    "    \n",
    "    return records\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f63579f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sites)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ccc57c0d",
=======
   "execution_count": 9,
   "id": "1b03ca19",
>>>>>>> 87e965b46c39f97ad5410632916b1d336604ff04
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting all dates...\n",
<<<<<<< HEAD
      "✓ Found 615 dates (up to today)\n",
      "  Date range: 2024-03-01 to 2025-11-05\n"
=======
      "✓ Found 610 dates (up to today)\n",
      "  Date range: 2024-03-01 to 2025-10-31\n"
>>>>>>> 87e965b46c39f97ad5410632916b1d336604ff04
     ]
    },
    {
     "data": {
      "text/plain": [
       "615"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_dates = get_all_dates(df)\n",
    "len(all_dates)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 51,
   "id": "8a857431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Extracting READINGS for NEW Morongo Site #2...\n",
      "  Extracting INV SETTINGS for NEW Morongo Site #2...\n",
      " Getting 3-week average sales for NEW Morongo Site #2...\n",
      " Getting 2-month average sales for NEW Morongo Site #2...\n",
      "  Extracting TANK SIZES for NEW Morongo Site #2...\n"
     ]
    }
   ],
   "source": [
    "all_inv_settings = []\n",
    "all_readings = []\n",
    "all_three_week_avgs = []\n",
    "all_two_month_avgs = []\n",
    "all_tank_sizes = []\n",
    "for site_row, site_name in sites:\n",
    "    if site_name != \"NEW Morongo Site #2\":\n",
    "        continue\n",
    "    # print(f\"\\nProcessing site: {site_name})\")\n",
    "    readings = extract_site_readings(df, site_row, site_name, all_dates)\n",
    "    all_readings.extend(readings)\n",
    "    inv_settings = extract_site_inv_settings(df, site_row, site_name)\n",
    "    all_inv_settings.extend(inv_settings)\n",
    "    three_week_avgs = get_three_week_avg(df, site_row, site_name, all_dates)\n",
    "    all_three_week_avgs.extend(three_week_avgs)\n",
    "    two_month_avgs = get_2_month_avg(df, site_row, site_name, all_dates)\n",
    "    all_two_month_avgs.extend(two_month_avgs)\n",
    "    tank_sizes = extract_site_tank_sizes(df, site_row, site_name)\n",
    "    all_tank_sizes.extend(tank_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0be16fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_readings = pd.DataFrame(all_readings)\n",
    "df_inv_settings = pd.DataFrame(all_inv_settings)\n",
    "df_three_week_avgs = pd.DataFrame(all_three_week_avgs)\n",
    "df_two_month_avgs = pd.DataFrame(all_two_month_avgs)\n",
    "df_tank_sizes = pd.DataFrame(all_tank_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb39adca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Site",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Product",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Tank_Number",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Desired_Level",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "3a3f0c01-e8ee-4dae-8ca9-4c713382ceeb",
       "rows": [
        [
         "0",
         "NEW Morongo Site #2",
         "87",
         "1",
         "20000.0"
        ],
        [
         "1",
         "NEW Morongo Site #2",
         "87",
         "2",
         "20000.0"
        ],
        [
         "2",
         "NEW Morongo Site #2",
         "91",
         "1",
         "12000.0"
        ],
        [
         "3",
         "NEW Morongo Site #2",
         "dsl",
         "1",
         "21000.0"
        ],
        [
         "4",
         "NEW Morongo Site #2",
         "dsl",
         "2",
         "21000.0"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Site</th>\n",
       "      <th>Product</th>\n",
       "      <th>Tank_Number</th>\n",
       "      <th>Desired_Level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NEW Morongo Site #2</td>\n",
       "      <td>87</td>\n",
       "      <td>1</td>\n",
       "      <td>20000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NEW Morongo Site #2</td>\n",
       "      <td>87</td>\n",
       "      <td>2</td>\n",
       "      <td>20000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NEW Morongo Site #2</td>\n",
       "      <td>91</td>\n",
       "      <td>1</td>\n",
       "      <td>12000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NEW Morongo Site #2</td>\n",
       "      <td>dsl</td>\n",
       "      <td>1</td>\n",
       "      <td>21000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NEW Morongo Site #2</td>\n",
       "      <td>dsl</td>\n",
       "      <td>2</td>\n",
       "      <td>21000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Site Product  Tank_Number  Desired_Level\n",
       "0  NEW Morongo Site #2      87            1        20000.0\n",
       "1  NEW Morongo Site #2      87            2        20000.0\n",
       "2  NEW Morongo Site #2      91            1        12000.0\n",
       "3  NEW Morongo Site #2     dsl            1        21000.0\n",
       "4  NEW Morongo Site #2     dsl            2        21000.0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tank_sizes\n"
=======
   "execution_count": 10,
   "id": "ee6acc08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_site_readings(df, site_row, site_name, date_columns):\n",
    "    \"\"\"Extract readings for a single site\"\"\"\n",
    "    print(f\"  Extracting READINGS for {site_name}...\")\n",
    "    \n",
    "    # Find READINGS section\n",
    "    reading_start_row = None\n",
    "    reading_end_row = None\n",
    "    \n",
    "    for offset in range(20):\n",
    "        row_idx = site_row + offset\n",
    "        if row_idx >= len(df):\n",
    "            break\n",
    "        \n",
    "        section_label = str(df.iloc[row_idx, 3]).strip() if pd.notna(df.iloc[row_idx, 3]) else \"\"\n",
    "        \n",
    "        if \"READINGS\" in section_label.upper():\n",
    "            reading_start_row = row_idx + 1\n",
    "            break\n",
    "    \n",
    "    if reading_start_row is None:\n",
    "        return []\n",
    "    \n",
    "    # Find end of READINGS section\n",
    "    for offset in range(15):\n",
    "        row_idx = reading_start_row + offset\n",
    "        if row_idx >= len(df):\n",
    "            break\n",
    "        \n",
    "        section_label = str(df.iloc[row_idx, 3]).strip() if pd.notna(df.iloc[row_idx, 3]) else \"\"\n",
    "        \n",
    "        if any(keyword in section_label.upper() for keyword in ['ULLAGE', 'LOADS', 'CARRIER', 'NOTES']):\n",
    "            reading_end_row = row_idx\n",
    "            break\n",
    "    \n",
    "    if reading_end_row is None:\n",
    "        reading_end_row = reading_start_row + 10\n",
    "    \n",
    "    # Scan READINGS section\n",
    "    records = []\n",
    "    products_found = {}\n",
    "    \n",
    "    for row_idx in range(reading_start_row, reading_end_row):\n",
    "        if row_idx >= len(df):\n",
    "            break\n",
    "        \n",
    "        product_cell = df.iloc[row_idx, 4]\n",
    "        \n",
    "        if pd.notna(product_cell):\n",
    "            product = str(product_cell).strip()\n",
    "            \n",
    "            for key in ['87', '88', '91', 'dsl', 'racing', 'red', 'total']:\n",
    "                if product.lower().startswith(key):\n",
    "                    if product not in products_found:\n",
    "                        products_found[product] = []\n",
    "                    products_found[product].append(row_idx)\n",
    "    \n",
    "    # Extract readings for each date\n",
    "    for col_idx, date in date_columns:\n",
    "        for product, row_indices in products_found.items():\n",
    "            record = {\n",
    "                'Date': date.strftime('%Y-%m-%d'),\n",
    "                'Site': site_name,\n",
    "                'Product': product\n",
    "            }\n",
    "            \n",
    "            for tank_num, row_idx in enumerate(row_indices, start=1):\n",
    "                value = df.iloc[row_idx, col_idx]\n",
    "                \n",
    "                if pd.notna(value):\n",
    "                    try:\n",
    "                        clean_val = str(value).replace(',', '').strip()\n",
    "                        numeric_val = float(clean_val) if clean_val else None\n",
    "                        record[f'Tank_{tank_num}_Reading'] = numeric_val\n",
    "                    except:\n",
    "                        record[f'Tank_{tank_num}_Reading'] = None\n",
    "                else:\n",
    "                    record[f'Tank_{tank_num}_Reading'] = None\n",
    "            \n",
    "            records.append(record)\n",
    "    \n",
    "    return records\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "85549bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_site_sales_actual(df, site_row, site_name, date_columns):\n",
    "    \"\"\"Extract actual sales for a single site\"\"\"\n",
    "    print(f\"  Extracting SALES (actual) for {site_name}...\")\n",
    "    \n",
    "    # Find SALES (actual) section\n",
    "    sales_start_row = None\n",
    "    \n",
    "    for offset in range(200):\n",
    "        row_idx = site_row + offset\n",
    "        if row_idx >= len(df):\n",
    "            break\n",
    "        \n",
    "        col1_label = str(df.iloc[row_idx, 1]).strip() if pd.notna(df.iloc[row_idx, 1]) else \"\"\n",
    "        col3_label = str(df.iloc[row_idx, 3]).strip() if pd.notna(df.iloc[row_idx, 3]) else \"\"\n",
    "        \n",
    "        # Look for SALES (actual) specifically, not SALES (projected)\n",
    "        if \"SALES\" in col1_label.upper() and \"ACTUAL\" in col1_label.upper():\n",
    "            sales_start_row = row_idx\n",
    "            break\n",
    "        elif \"ACTUAL\" in col3_label.upper() and \"SALES\" in col1_label.upper():\n",
    "            sales_start_row = row_idx\n",
    "            break\n",
    "    \n",
    "    if sales_start_row is None:\n",
    "        return []\n",
    "    \n",
    "    # Extract products in SALES (actual) section\n",
    "    records = []\n",
    "    products_found = {}\n",
    "    \n",
    "    for row_idx in range(sales_start_row, sales_start_row + 10):\n",
    "        if row_idx >= len(df):\n",
    "            break\n",
    "        \n",
    "        product_cell = df.iloc[row_idx, 4]\n",
    "        \n",
    "        if pd.notna(product_cell):\n",
    "            product = str(product_cell).strip()\n",
    "            if \"READING\" in product.upper():\n",
    "                # print(f\"    Reached end of products at row {row_idx}.\")\n",
    "                break\n",
    "            # Get base product (87, 88, racing, red, 91, dsl) - include totals\n",
    "            base_product = None\n",
    "            is_total = False\n",
    "            \n",
    "            if \"87\" in product:\n",
    "                base_product = product\n",
    "                is_total = \"total\" in product.lower()\n",
    "            elif \"88\" in product:\n",
    "                base_product = product\n",
    "                is_total = \"total\" in product.lower()\n",
    "            elif \"91\" in product:\n",
    "                base_product = product\n",
    "                is_total = \"total\" in product.lower()\n",
    "            elif \"dsl\" in product.lower():\n",
    "                base_product = product\n",
    "                is_total = \"total\" in product.lower()\n",
    "            elif \"racing\" in product.lower():\n",
    "                base_product = product\n",
    "                is_total = \"total\" in product.lower()\n",
    "            elif \"red\" in product.lower():\n",
    "                base_product = product\n",
    "                is_total = \"total\" in product.lower()\n",
    "\n",
    "\n",
    "            if base_product:\n",
    "                products_found[product] = {\n",
    "                    'row_idx': row_idx,\n",
    "                    'base_product': base_product,\n",
    "                    'is_total': is_total\n",
    "                }\n",
    "    \n",
    "    # Extract sales for each date\n",
    "    for col_idx, date in date_columns:\n",
    "        for product_key, product_info in products_found.items():\n",
    "            row_idx = product_info['row_idx']\n",
    "            value = df.iloc[row_idx, col_idx]\n",
    "            \n",
    "            if pd.notna(value):\n",
    "                try:\n",
    "                    clean_val = str(value).replace(',', '').strip()\n",
    "                    sales_val = float(clean_val) if clean_val else None\n",
    "                    \n",
    "                    if sales_val is not None:\n",
    "                        records.append({\n",
    "                            'Date': date.strftime('%Y-%m-%d'),\n",
    "                            'Site': site_name,\n",
    "                            'Product': product_info['base_product'],\n",
    "                            'Sales_Actual': sales_val,\n",
    "                            'Is_Total': product_info['is_total']\n",
    "                        })\n",
    "                except:\n",
    "                    pass\n",
    "    \n",
    "    return records\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ca356a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_three_week_avg(df, site_row, site_name, all_dates):    \n",
    "    \"\"\"Get 3-week average sales for a site\"\"\"\n",
    "    print(f\" Getting 3-week average sales for {site_name}...\")\n",
    "    avg_start_row = None\n",
    "    product_name = None\n",
    "    avg_end_row = None\n",
    "    for offset in range(200):\n",
    "        row_idx = site_row + offset\n",
    "        if row_idx >= len(df):\n",
    "            break\n",
    "        \n",
    "        section_label = str(df.iloc[row_idx-1, 3]).strip() if pd.notna(df.iloc[row_idx-1, 3]) else \"\"\n",
    "        avg_col = str(df.iloc[row_idx, 4]).strip() if pd.notna(df.iloc[row_idx, 4]) else \"\"\n",
    "\n",
    "\n",
    "        if \"3 WK AVG\" in avg_col.upper():\n",
    "            avg_start_row = row_idx + 1\n",
    "            break\n",
    "    \n",
    "    if avg_start_row is None:\n",
    "        return []\n",
    "\n",
    "    # Find end of Avg Section\n",
    "    for offset in range(200):\n",
    "        row_idx = avg_start_row + offset\n",
    "        if row_idx >= len(df):\n",
    "            break\n",
    "        \n",
    "        section_label = str(df.iloc[row_idx, 3]).strip() if pd.notna(df.iloc[row_idx, 3]) else \"\"\n",
    "        \n",
    "        if any(keyword in section_label.upper() for keyword in ['ACTUAL']):\n",
    "            avg_end_row = row_idx\n",
    "            break\n",
    "    \n",
    "    if avg_end_row is None:\n",
    "        avg_end_row = avg_start_row + 100\n",
    "\n",
    "    records = []\n",
    "    products_found = {}\n",
    "\n",
    "    for row_idx in range(avg_start_row, avg_end_row):\n",
    "        if row_idx >= len(df):\n",
    "            break\n",
    "        \n",
    "        product_cell = df.iloc[row_idx-2, 4]\n",
    "        \n",
    "        if pd.notna(product_cell):\n",
    "            product = str(product_cell).strip()\n",
    "            \n",
    "            if any(key in product for key in ['87', '88', '91', 'dsl', 'racing', 'red']):\n",
    "                if product not in products_found:\n",
    "                    products_found[product] = []\n",
    "                \n",
    "                products_found[product].append(row_idx)\n",
    "\n",
    "    for col_idx, date in all_dates:\n",
    "        for product, row_indices in products_found.items():\n",
    "            record = {\n",
    "                'Date': date.strftime('%Y-%m-%d'),\n",
    "                'Site': site_name,\n",
    "                'Product': product\n",
    "            }\n",
    "            for tank_num, row_idx in enumerate(row_indices, start=1):\n",
    "                value = df.iloc[row_idx-1, col_idx]\n",
    "                if pd.notna(value):\n",
    "                    try:\n",
    "                        clean_val = str(value).replace(',', '').strip()\n",
    "                        avg_val = float(clean_val) if clean_val else None\n",
    "                        record[f'Tank_{tank_num}_3_Week_Avg'] = avg_val\n",
    "                    except:\n",
    "                        record[f'Tank_{tank_num}_3_Week_Avg'] = None\n",
    "                else:\n",
    "                    record[f'Tank_{tank_num}_3_Week_Avg'] = None\n",
    "            \n",
    "            records.append(record)\n",
    "\n",
    "    return records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90708fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_2_month_avg(df, site_row, site_name, all_dates):    \n",
    "    \"\"\"Get 2-month average sales for a site\"\"\"\n",
    "    print(f\" Getting 2-month average sales for {site_name}...\")\n",
    "    avg_start_row = None\n",
    "    product_name = None\n",
    "    avg_end_row = None\n",
    "    for offset in range(200):\n",
    "        row_idx = site_row + offset\n",
    "        if row_idx >= len(df):\n",
    "            break\n",
    "        \n",
    "        section_label = str(df.iloc[row_idx-1, 3]).strip() if pd.notna(df.iloc[row_idx-1, 3]) else \"\"\n",
    "        avg_col = str(df.iloc[row_idx, 4]).strip() if pd.notna(df.iloc[row_idx, 4]) else \"\"\n",
    "\n",
    "\n",
    "        if \"2 MO AVG\" in avg_col.upper():\n",
    "            avg_start_row = row_idx + 1\n",
    "            break\n",
    "    \n",
    "    if avg_start_row is None:\n",
    "        return []\n",
    "\n",
    "    # Find end of Avg Section\n",
    "    for offset in range(200):\n",
    "        row_idx = avg_start_row + offset\n",
    "        if row_idx >= len(df):\n",
    "            break\n",
    "        \n",
    "        section_label = str(df.iloc[row_idx, 3]).strip() if pd.notna(df.iloc[row_idx, 3]) else \"\"\n",
    "        \n",
    "        if any(keyword in section_label.upper() for keyword in ['ACTUAL']):\n",
    "            avg_end_row = row_idx\n",
    "            break\n",
    "    \n",
    "    if avg_end_row is None:\n",
    "        avg_end_row = avg_start_row + 100\n",
    "\n",
    "    records = []\n",
    "    products_found = {}\n",
    "\n",
    "    for row_idx in range(avg_start_row, avg_end_row):\n",
    "        if row_idx >= len(df):\n",
    "            break\n",
    "        \n",
    "        product_cell = df.iloc[row_idx-3, 4]\n",
    "        \n",
    "        if pd.notna(product_cell):\n",
    "            product = str(product_cell).strip()\n",
    "            \n",
    "            if any(key in product for key in ['87', '88', '91', 'dsl', 'racing', 'red']):\n",
    "                if product not in products_found:\n",
    "                    products_found[product] = []\n",
    "                \n",
    "                products_found[product].append(row_idx)\n",
    "\n",
    "    for col_idx, date in all_dates:\n",
    "        for product, row_indices in products_found.items():\n",
    "            record = {\n",
    "                'Date': date.strftime('%Y-%m-%d'),\n",
    "                'Site': site_name,\n",
    "                'Product': product\n",
    "            }\n",
    "            for tank_num, row_idx in enumerate(row_indices, start=1):\n",
    "                value = df.iloc[row_idx-1, col_idx]\n",
    "                if pd.notna(value):\n",
    "                    try:\n",
    "                        clean_val = str(value).replace(',', '').strip()\n",
    "                        avg_val = float(clean_val) if clean_val else None\n",
    "                        record[f'Tank_{tank_num}_2_Month_Avg'] = avg_val\n",
    "                    except:\n",
    "                        record[f'Tank_{tank_num}_2_Month_Avg'] = None\n",
    "                else:\n",
    "                    record[f'Tank_{tank_num}_2_Month_Avg'] = None\n",
    "\n",
    "            records.append(record)\n",
    "\n",
    "    return records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea019e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "for site_row , site_name in sites:\n",
    "    print(f\"\\n{site_name}:\")\n",
    "\n",
    "    print(f\"  Extracting SALES (actual) for {site_name}...\")\n",
    "    sales_start_row = None\n",
    "\n",
    "    for offset in range(40):\n",
    "        row_idx = site_row + offset\n",
    "        if row_idx >= len(df):\n",
    "            break\n",
    "        \n",
    "        col1_label = str(df.iloc[row_idx, 1]).strip() if pd.notna(df.iloc[row_idx, 1]) else \"\"\n",
    "        col3_label = str(df.iloc[row_idx, 3]).strip() if pd.notna(df.iloc[row_idx, 3]) else \"\"\n",
    "\n",
    "        if \"SALES\" in col1_label.upper() and \"ACTUAL\" in col3_label.upper():\n",
    "            sales_start_row = row_idx\n",
    "            break\n",
    "        elif \"ACTUAL\" in col3_label.upper() and 'SALES' in col1_label.upper():\n",
    "            sales_start_row = row_idx\n",
    "            break\n",
    "    print(f\"    Found SALES (actual) row at index {sales_start_row}\")\n",
    "\n",
    "    if sales_start_row is None:\n",
    "        print(f\"    ⚠️ SALES (actual) row not found for {site_name}, skipping...\")\n",
    "        break\n",
    "    records = []\n",
    "    products_found = {}\n",
    "\n",
    "    for row_idx in range(sales_start_row, sales_start_row+10):\n",
    "        if row_idx >= len(df):\n",
    "            break\n",
    "\n",
    "        product_cell = df.iloc[row_idx, 4]\n",
    "        # print(f\"    Checking row {row_idx}, product cell: {product_cell}\")\n",
    "\n",
    "        if pd.notna(product_cell):\n",
    "            product = str(product_cell).strip()\n",
    "            # print(f\"    Found product: {product}\")\n",
    "            if \"READING\" in product.upper():\n",
    "                # print(f\"    Reached end of products at row {row_idx}.\")\n",
    "                break\n",
    "            base_product = None\n",
    "            is_total = False\n",
    "\n",
    "            if \"87\" in product:\n",
    "                base_product = product\n",
    "                is_total = \"total\" in product.upper()\n",
    "            elif \"91\" in product:\n",
    "                base_product = product\n",
    "                is_total = \"total\" in product.upper()\n",
    "            elif \"dsl\" in product.lower():\n",
    "                base_product = product\n",
    "                is_total = \"total\" in product.lower()\n",
    "            \n",
    "            if base_product:\n",
    "                products_found[product] = {\n",
    "                    'row_idx': row_idx,\n",
    "                    'base_product': base_product,\n",
    "                    'is_total': is_total\n",
    "                }\n",
    "\n",
    "    print(f\"    Products found so far: {products_found}\")\n",
    "\n",
    "    for col_idx, date in all_dates:\n",
    "        for _, product_info in products_found.items():\n",
    "            row_idx = product_info['row_idx']\n",
    "            value = df.iloc[row_idx, col_idx]\n",
    "\n",
    "            print(f\"      Date: {date.date()}, Product: {product_info['base_product']}, Value: {value}, Col: {col_idx}, Row: {row_idx}\")\n",
    "    break\n"
>>>>>>> 87e965b46c39f97ad5410632916b1d336604ff04
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fa5069d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Getting 3-week average sales for Salton Sea | Red Earth...\n",
      "   Found 3 WK AVG at row 313\n"
     ]
    }
   ],
   "source": [
    "for site_row, site_name in sites:\n",
    "    if site_name != \"Salton Sea | Red Earth\":\n",
    "        continue\n",
    "        \"\"\"Get 3-week average sales for a site\"\"\"\n",
    "    print(f\" Getting 3-week average sales for {site_name}...\")\n",
    "    avg_start_row = None\n",
    "    product_name = None\n",
    "    avg_end_row = None\n",
    "    for offset in range(200):\n",
    "        row_idx = site_row + offset\n",
    "        if row_idx >= len(df):\n",
    "            break\n",
    "        \n",
    "        section_label = str(df.iloc[row_idx-1, 3]).strip() if pd.notna(df.iloc[row_idx-1, 3]) else \"\"\n",
    "        avg_col = str(df.iloc[row_idx, 4]).strip() if pd.notna(df.iloc[row_idx, 4]) else \"\"\n",
    "\n",
    "\n",
    "        if \"3 WK AVG\" in avg_col.upper():\n",
    "            avg_start_row = row_idx + 1\n",
    "            print(f\"   Found 3 WK AVG at row {avg_start_row}\")\n",
    "            break\n",
    "    \n",
    "    if avg_start_row is None:\n",
    "        print(\"   3 WK AVG section not found, skipping...\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a95211f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Getting 3-week average sales for OLD Morongo | Cabazon...\n",
      "    ✓ 1830 3-week average records\n",
      " Getting 2-month average sales for OLD Morongo | Cabazon...\n",
      " Getting 3-week average sales for NEW Morongo Site #2...\n",
      "    ✓ 1830 3-week average records\n",
      " Getting 2-month average sales for NEW Morongo Site #2...\n",
      " Getting 3-week average sales for Fort Independence...\n",
      "    ✓ 1830 3-week average records\n",
      " Getting 2-month average sales for Fort Independence...\n",
      " Getting 3-week average sales for Campo | Golden Acorn...\n",
      "    ✓ 1830 3-week average records\n",
      " Getting 2-month average sales for Campo | Golden Acorn...\n",
      " Getting 3-week average sales for Bishop | Pauite Palace...\n",
      "    ✓ 1830 3-week average records\n",
      " Getting 2-month average sales for Bishop | Pauite Palace...\n",
      " Getting 3-week average sales for Bishop Pauite 2 Nobi...\n",
      "    ✓ 1830 3-week average records\n",
      " Getting 2-month average sales for Bishop Pauite 2 Nobi...\n",
      " Getting 3-week average sales for Pechanga | Temecula...\n",
      "    ✓ 1830 3-week average records\n",
      " Getting 2-month average sales for Pechanga | Temecula...\n",
      " Getting 3-week average sales for Salton Sea | Red Earth...\n",
      "    ✓ 4270 3-week average records\n",
      " Getting 2-month average sales for Salton Sea | Red Earth...\n",
      " Getting 3-week average sales for Cahuilla | Anza...\n",
      "    ✓ 1830 3-week average records\n",
      " Getting 2-month average sales for Cahuilla | Anza...\n",
      " Getting 3-week average sales for La Jolla Trading Post...\n",
      "    ✓ 1830 3-week average records\n",
      " Getting 2-month average sales for La Jolla Trading Post...\n",
      " Getting 3-week average sales for Eagle Feather | Tule River...\n",
      "    ✓ 1830 3-week average records\n",
      " Getting 2-month average sales for Eagle Feather | Tule River...\n",
      " Getting 3-week average sales for Sycuan | El Cajon...\n",
      "    ✓ 1830 3-week average records\n",
      " Getting 2-month average sales for Sycuan | El Cajon...\n",
      " Getting 3-week average sales for Rincon | Valley Center...\n",
      "    ✓ 1830 3-week average records\n",
      " Getting 2-month average sales for Rincon | Valley Center...\n",
      " Getting 3-week average sales for Santa Rosa Pit Stop...\n",
      "    ✓ 1830 3-week average records\n",
      " Getting 2-month average sales for Santa Rosa Pit Stop...\n",
      " Getting 3-week average sales for Fort Mojave Smoke Shop...\n",
      "    ✓ 1830 3-week average records\n",
      " Getting 2-month average sales for Fort Mojave Smoke Shop...\n",
      " Getting 3-week average sales for Thalypo | Fort Mojave...\n",
      "    ✓ 3660 3-week average records\n",
      " Getting 2-month average sales for Thalypo | Fort Mojave...\n",
      " Getting 3-week average sales for Pala...\n",
      "    ✓ 1830 3-week average records\n",
      " Getting 2-month average sales for Pala...\n",
      " Getting 3-week average sales for Shivwits | Utah...\n",
      "    ✓ 3050 3-week average records\n",
      " Getting 2-month average sales for Shivwits | Utah...\n",
      " Getting 3-week average sales for San Pasqual | Valley View...\n",
      "    ✓ 1830 3-week average records\n",
      " Getting 2-month average sales for San Pasqual | Valley View...\n",
      " Getting 3-week average sales for Barona...\n",
      "    ✓ 1830 3-week average records\n",
      " Getting 2-month average sales for Barona...\n",
      " Getting 3-week average sales for Kanosh | Pahvant Travel...\n",
      "    ✓ 2440 3-week average records\n",
      " Getting 2-month average sales for Kanosh | Pahvant Travel...\n",
      " Getting 3-week average sales for Santa Ysabel...\n",
      "    ✓ 1830 3-week average records\n",
      " Getting 2-month average sales for Santa Ysabel...\n",
      " Getting 3-week average sales for Palms | Coachella...\n",
      "    ✓ 4880 3-week average records\n",
      " Getting 2-month average sales for Palms | Coachella...\n",
      " Getting 3-week average sales for Kaibab | Red Cliffs...\n",
      "    ✓ 1830 3-week average records\n",
      " Getting 2-month average sales for Kaibab | Red Cliffs...\n",
      " Getting 3-week average sales for Viejas | Alpine...\n",
      "    ✓ 2440 3-week average records\n",
      " Getting 2-month average sales for Viejas | Alpine...\n",
      " Getting 3-week average sales for Chumash...\n",
      "    ✓ 1830 3-week average records\n",
      " Getting 2-month average sales for Chumash...\n"
     ]
    }
   ],
   "source": [
    "all_readings = []\n",
    "all_loads = []\n",
    "all_tank_sizes = []\n",
    "all_inv_settings = []\n",
    "all_sales_actual = []\n",
    "all_three_week_avg = []\n",
    "all_2_month_avg = []\n",
    "for site_row, site_name in sites:\n",
    "    # readings = extract_site_readings(df, site_row, site_name, all_dates)\n",
    "    # all_readings.extend(readings)\n",
    "    # print(f\"    ✓ {len(readings)} reading records\")\n",
    "    # # Extract sales actual\n",
    "    # sales_actual = extract_site_sales_actual(df, site_row, site_name, all_dates)\n",
    "    # all_sales_actual.extend(sales_actual)\n",
    "    # print(f\"    ✓ {len(sales_actual)} sales actual records\")\n",
    "\n",
    "    three_week_avg = get_three_week_avg(df, site_row, site_name, all_dates)\n",
    "    all_three_week_avg.extend(three_week_avg)\n",
    "    print(f\"    ✓ {len(three_week_avg)} 3-week average records\")\n",
    "\n",
    "    two_month_avg = get_2_month_avg(df, site_row, site_name, all_dates)\n",
    "    all_2_month_avg.extend(two_month_avg)\n",
    "\n",
    "# df_readings = pd.DataFrame(all_readings)\n",
    "# df_sales_actual = pd.DataFrame(all_sales_actual)\n",
    "df_three_week_avg = pd.DataFrame(all_three_week_avg)\n",
    "df_2_month_avg = pd.DataFrame(all_2_month_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "991a8194",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Date",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Site",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Product",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Tank_1_3_Week_Avg",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Tank_2_3_Week_Avg",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "58272904-9a40-4a75-a977-166dd198ba3c",
       "rows": [
        [
         "0",
         "2024-03-01",
         "OLD Morongo | Cabazon",
         "87",
         "29734.0",
         null
        ],
        [
         "1",
         "2024-03-01",
         "OLD Morongo | Cabazon",
         "91",
         "5899.0",
         null
        ],
        [
         "2",
         "2024-03-01",
         "OLD Morongo | Cabazon",
         "dsl",
         "4792.0",
         null
        ],
        [
         "3",
         "2024-03-02",
         "OLD Morongo | Cabazon",
         "87",
         "32464.0",
         null
        ],
        [
         "4",
         "2024-03-02",
         "OLD Morongo | Cabazon",
         "91",
         "7807.0",
         null
        ],
        [
         "5",
         "2024-03-02",
         "OLD Morongo | Cabazon",
         "dsl",
         "4413.0",
         null
        ],
        [
         "6",
         "2024-03-03",
         "OLD Morongo | Cabazon",
         "87",
         "29180.0",
         null
        ],
        [
         "7",
         "2024-03-03",
         "OLD Morongo | Cabazon",
         "91",
         "6792.0",
         null
        ],
        [
         "8",
         "2024-03-03",
         "OLD Morongo | Cabazon",
         "dsl",
         "3849.0",
         null
        ],
        [
         "9",
         "2024-03-04",
         "OLD Morongo | Cabazon",
         "87",
         "28912.0",
         null
        ],
        [
         "10",
         "2024-03-04",
         "OLD Morongo | Cabazon",
         "91",
         "4523.0",
         null
        ],
        [
         "11",
         "2024-03-04",
         "OLD Morongo | Cabazon",
         "dsl",
         "3563.0",
         null
        ],
        [
         "12",
         "2024-03-05",
         "OLD Morongo | Cabazon",
         "87",
         "23307.0",
         null
        ],
        [
         "13",
         "2024-03-05",
         "OLD Morongo | Cabazon",
         "91",
         "4467.0",
         null
        ],
        [
         "14",
         "2024-03-05",
         "OLD Morongo | Cabazon",
         "dsl",
         "3453.0",
         null
        ],
        [
         "15",
         "2024-03-06",
         "OLD Morongo | Cabazon",
         "87",
         "24308.0",
         null
        ],
        [
         "16",
         "2024-03-06",
         "OLD Morongo | Cabazon",
         "91",
         "3761.0",
         null
        ],
        [
         "17",
         "2024-03-06",
         "OLD Morongo | Cabazon",
         "dsl",
         "4176.0",
         null
        ],
        [
         "18",
         "2024-03-07",
         "OLD Morongo | Cabazon",
         "87",
         "24848.0",
         null
        ],
        [
         "19",
         "2024-03-07",
         "OLD Morongo | Cabazon",
         "91",
         "4814.0",
         null
        ],
        [
         "20",
         "2024-03-07",
         "OLD Morongo | Cabazon",
         "dsl",
         "4458.0",
         null
        ],
        [
         "21",
         "2024-03-08",
         "OLD Morongo | Cabazon",
         "87",
         "31189.0",
         null
        ],
        [
         "22",
         "2024-03-08",
         "OLD Morongo | Cabazon",
         "91",
         "6028.0",
         null
        ],
        [
         "23",
         "2024-03-08",
         "OLD Morongo | Cabazon",
         "dsl",
         "4679.0",
         null
        ],
        [
         "24",
         "2024-03-09",
         "OLD Morongo | Cabazon",
         "87",
         "29525.0",
         null
        ],
        [
         "25",
         "2024-03-09",
         "OLD Morongo | Cabazon",
         "91",
         "7093.0",
         null
        ],
        [
         "26",
         "2024-03-09",
         "OLD Morongo | Cabazon",
         "dsl",
         "3897.0",
         null
        ],
        [
         "27",
         "2024-03-10",
         "OLD Morongo | Cabazon",
         "87",
         "30599.0",
         null
        ],
        [
         "28",
         "2024-03-10",
         "OLD Morongo | Cabazon",
         "91",
         "7088.0",
         null
        ],
        [
         "29",
         "2024-03-10",
         "OLD Morongo | Cabazon",
         "dsl",
         "4257.0",
         null
        ],
        [
         "30",
         "2024-03-11",
         "OLD Morongo | Cabazon",
         "87",
         "27542.0",
         null
        ],
        [
         "31",
         "2024-03-11",
         "OLD Morongo | Cabazon",
         "91",
         "4632.0",
         null
        ],
        [
         "32",
         "2024-03-11",
         "OLD Morongo | Cabazon",
         "dsl",
         "4044.0",
         null
        ],
        [
         "33",
         "2024-03-12",
         "OLD Morongo | Cabazon",
         "87",
         "24124.0",
         null
        ],
        [
         "34",
         "2024-03-12",
         "OLD Morongo | Cabazon",
         "91",
         "4505.0",
         null
        ],
        [
         "35",
         "2024-03-12",
         "OLD Morongo | Cabazon",
         "dsl",
         "3906.0",
         null
        ],
        [
         "36",
         "2024-03-13",
         "OLD Morongo | Cabazon",
         "87",
         "24072.0",
         null
        ],
        [
         "37",
         "2024-03-13",
         "OLD Morongo | Cabazon",
         "91",
         "3951.0",
         null
        ],
        [
         "38",
         "2024-03-13",
         "OLD Morongo | Cabazon",
         "dsl",
         "4011.0",
         null
        ],
        [
         "39",
         "2024-03-14",
         "OLD Morongo | Cabazon",
         "87",
         "26215.0",
         null
        ],
        [
         "40",
         "2024-03-14",
         "OLD Morongo | Cabazon",
         "91",
         "4761.0",
         null
        ],
        [
         "41",
         "2024-03-14",
         "OLD Morongo | Cabazon",
         "dsl",
         "4676.0",
         null
        ],
        [
         "42",
         "2024-03-15",
         "OLD Morongo | Cabazon",
         "87",
         "30990.0",
         null
        ],
        [
         "43",
         "2024-03-15",
         "OLD Morongo | Cabazon",
         "91",
         "6167.0",
         null
        ],
        [
         "44",
         "2024-03-15",
         "OLD Morongo | Cabazon",
         "dsl",
         "4538.0",
         null
        ],
        [
         "45",
         "2024-03-16",
         "OLD Morongo | Cabazon",
         "87",
         "27143.0",
         null
        ],
        [
         "46",
         "2024-03-16",
         "OLD Morongo | Cabazon",
         "91",
         "6695.0",
         null
        ],
        [
         "47",
         "2024-03-16",
         "OLD Morongo | Cabazon",
         "dsl",
         "4010.0",
         null
        ],
        [
         "48",
         "2024-03-17",
         "OLD Morongo | Cabazon",
         "87",
         "29820.0",
         null
        ],
        [
         "49",
         "2024-03-17",
         "OLD Morongo | Cabazon",
         "91",
         "6892.0",
         null
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 57340
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Site</th>\n",
       "      <th>Product</th>\n",
       "      <th>Tank_1_3_Week_Avg</th>\n",
       "      <th>Tank_2_3_Week_Avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-03-01</td>\n",
       "      <td>OLD Morongo | Cabazon</td>\n",
       "      <td>87</td>\n",
       "      <td>29734.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-03-01</td>\n",
       "      <td>OLD Morongo | Cabazon</td>\n",
       "      <td>91</td>\n",
       "      <td>5899.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-03-01</td>\n",
       "      <td>OLD Morongo | Cabazon</td>\n",
       "      <td>dsl</td>\n",
       "      <td>4792.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-03-02</td>\n",
       "      <td>OLD Morongo | Cabazon</td>\n",
       "      <td>87</td>\n",
       "      <td>32464.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-03-02</td>\n",
       "      <td>OLD Morongo | Cabazon</td>\n",
       "      <td>91</td>\n",
       "      <td>7807.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57335</th>\n",
       "      <td>2025-10-30</td>\n",
       "      <td>Chumash</td>\n",
       "      <td>91</td>\n",
       "      <td>299.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57336</th>\n",
       "      <td>2025-10-30</td>\n",
       "      <td>Chumash</td>\n",
       "      <td>dsl</td>\n",
       "      <td>1276.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57337</th>\n",
       "      <td>2025-10-31</td>\n",
       "      <td>Chumash</td>\n",
       "      <td>87</td>\n",
       "      <td>4876.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57338</th>\n",
       "      <td>2025-10-31</td>\n",
       "      <td>Chumash</td>\n",
       "      <td>91</td>\n",
       "      <td>1877.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57339</th>\n",
       "      <td>2025-10-31</td>\n",
       "      <td>Chumash</td>\n",
       "      <td>dsl</td>\n",
       "      <td>-273.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>57340 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Date                   Site Product  Tank_1_3_Week_Avg  \\\n",
       "0      2024-03-01  OLD Morongo | Cabazon      87            29734.0   \n",
       "1      2024-03-01  OLD Morongo | Cabazon      91             5899.0   \n",
       "2      2024-03-01  OLD Morongo | Cabazon     dsl             4792.0   \n",
       "3      2024-03-02  OLD Morongo | Cabazon      87            32464.0   \n",
       "4      2024-03-02  OLD Morongo | Cabazon      91             7807.0   \n",
       "...           ...                    ...     ...                ...   \n",
       "57335  2025-10-30                Chumash      91              299.0   \n",
       "57336  2025-10-30                Chumash     dsl             1276.0   \n",
       "57337  2025-10-31                Chumash      87             4876.0   \n",
       "57338  2025-10-31                Chumash      91             1877.0   \n",
       "57339  2025-10-31                Chumash     dsl             -273.0   \n",
       "\n",
       "       Tank_2_3_Week_Avg  \n",
       "0                    NaN  \n",
       "1                    NaN  \n",
       "2                    NaN  \n",
       "3                    NaN  \n",
       "4                    NaN  \n",
       "...                  ...  \n",
       "57335                NaN  \n",
       "57336                NaN  \n",
       "57337                NaN  \n",
       "57338                NaN  \n",
       "57339                NaN  \n",
       "\n",
       "[57340 rows x 5 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_three_week_avg"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
