{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e77bf5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "from io import StringIO\n",
    "from datetime import datetime\n",
    "import argparse\n",
    "import os\n",
    "from site_identifier import identify_sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d3b2c8f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data from Google Sheets...\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Fetch Google Sheets data\"\"\"\n",
    "print(\"Fetching data from Google Sheets...\")\n",
    "response = requests.get(GOOGLE_SHEETS_URL_2, timeout=30)\n",
    "response.raise_for_status()\n",
    "df = pd.read_csv(StringIO(response.text), header=None, low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "60b830c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "097e31f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identifying sites dynamically...\n",
      "Strategy: Finding 'INV. SETTING' labels and extracting site names\n",
      "\n",
      "  ✓ Row 4: Chukchansi | Coarsegold\n",
      "  ✓ Row 51: Yokut | OLD Lemoore\n",
      "  ✓ Row 99: Yokut 2\n",
      "  ✓ Row 142: Coyote Valley | Redwood\n",
      "  ✓ Row 177: Robinson | Pomo Pumps\n",
      "  ✓ Row 212: Diamond Mt. | Susanville\n",
      "  ✓ Row 247: Feather / Falls Upper\n",
      "  ✓ Row 282: Feather Falls | Lower\n",
      "  ✓ Row 329: Berry Creek | Maidu Mart\n",
      "  ✓ Row 372: Hidden Oaks | Covelo\n",
      "  ✓ Row 407: Pit River | Tamarack\n",
      "  ✓ Row 442: Chimney Rock | Alturas\n",
      "  ✓ Row 477: Shingle Springs | Express\n",
      "  ✓ Row 512: Cedarville | Rabbit Traxx\n",
      "  ✓ Row 548: Bear Creek | Tuolumne\n",
      "  ✓ Row 591: Middletown | Uncle Buddies\n",
      "  ✓ Row 626: Rolling Hills | Paskenta\n",
      "  ✓ Row 661: Colusa\n",
      "  ✓ Row 704: Enterprise | Hard Rock\n",
      "  ✓ Row 739: Buena Vista\n",
      "  ✓ Row 775: Big Valley\n",
      "  ✓ Row 826: Jackson Rancheria\n",
      "\n",
      "✓ Total sites identified: 22\n"
     ]
    }
   ],
   "source": [
    "sites = identify_sites(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e935cba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_dates(df, start_col=6):\n",
    "    \"\"\"Extract all date columns from the sheet (up to today only)\"\"\"\n",
    "    print(\"\\nExtracting all dates...\")\n",
    "    dates_row = df.iloc[0, start_col:]\n",
    "    \n",
    "    today = pd.Timestamp.now().normalize()  # Get today's date at midnight\n",
    "    \n",
    "    date_data = []\n",
    "    for col_idx, date_val in enumerate(dates_row, start=start_col):\n",
    "        if pd.notna(date_val):\n",
    "            try:\n",
    "                parsed = pd.to_datetime(str(date_val), format='%b-%d-%y', errors='coerce')\n",
    "                if parsed and parsed <= today:  # Only include dates up to today\n",
    "                    date_data.append((col_idx, parsed))\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "    print(f\"✓ Found {len(date_data)} dates (up to today)\")\n",
    "    if date_data:\n",
    "        print(f\"  Date range: {date_data[0][1].date()} to {date_data[-1][1].date()}\")\n",
    "    return date_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d2d2f2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_site_readings(df, site_row, site_name, date_columns):\n",
    "    \"\"\"Extract readings for a single site\"\"\"\n",
    "    print(f\"  Extracting READINGS for {site_name}...\")\n",
    "    \n",
    "    # Find READINGS section\n",
    "    reading_start_row = None\n",
    "    reading_end_row = None\n",
    "    \n",
    "    for offset in range(20):\n",
    "        row_idx = site_row + offset\n",
    "        if row_idx >= len(df):\n",
    "            break\n",
    "        \n",
    "        section_label = str(df.iloc[row_idx, 3]).strip() if pd.notna(df.iloc[row_idx, 3]) else \"\"\n",
    "        \n",
    "        if \"READINGS\" in section_label.upper():\n",
    "            reading_start_row = row_idx + 1\n",
    "            break\n",
    "    \n",
    "    if reading_start_row is None:\n",
    "        return []\n",
    "    \n",
    "    # Find end of READINGS section\n",
    "    for offset in range(15):\n",
    "        row_idx = reading_start_row + offset\n",
    "        if row_idx >= len(df):\n",
    "            break\n",
    "        \n",
    "        section_label = str(df.iloc[row_idx, 3]).strip() if pd.notna(df.iloc[row_idx, 3]) else \"\"\n",
    "        \n",
    "        if any(keyword in section_label.upper() for keyword in ['ULLAGE', 'LOADS', 'CARRIER', 'NOTES']):\n",
    "            reading_end_row = row_idx\n",
    "            break\n",
    "    \n",
    "    if reading_end_row is None:\n",
    "        reading_end_row = reading_start_row + 10\n",
    "    \n",
    "    # Scan READINGS section\n",
    "    records = []\n",
    "    products_found = {}\n",
    "    \n",
    "    for row_idx in range(reading_start_row, reading_end_row):\n",
    "        if row_idx >= len(df):\n",
    "            break\n",
    "        \n",
    "        product_cell = df.iloc[row_idx, 4]\n",
    "        \n",
    "        if pd.notna(product_cell):\n",
    "            product = str(product_cell).strip()\n",
    "            \n",
    "            if any(key in product for key in ['87', '88', '91', 'dsl', 'racing', 'red']):\n",
    "                if product not in products_found:\n",
    "                    products_found[product] = []\n",
    "                \n",
    "                products_found[product].append(row_idx)\n",
    "    \n",
    "    # Extract readings for each date\n",
    "    for col_idx, date in date_columns:\n",
    "        for product, row_indices in products_found.items():\n",
    "            record = {\n",
    "                'Date': date.strftime('%Y-%m-%d'),\n",
    "                'Site': site_name,\n",
    "                'Product': product\n",
    "            }\n",
    "            \n",
    "            for tank_num, row_idx in enumerate(row_indices, start=1):\n",
    "                value = df.iloc[row_idx, col_idx]\n",
    "                \n",
    "                if pd.notna(value):\n",
    "                    try:\n",
    "                        clean_val = str(value).replace(',', '').strip()\n",
    "                        numeric_val = float(clean_val) if clean_val else None\n",
    "                        record[f'Tank_{tank_num}_Reading'] = numeric_val\n",
    "                    except:\n",
    "                        record[f'Tank_{tank_num}_Reading'] = None\n",
    "                else:\n",
    "                    record[f'Tank_{tank_num}_Reading'] = None\n",
    "            \n",
    "            records.append(record)\n",
    "    \n",
    "    return records\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd864757",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_three_week_avg(df, site_row, site_name, all_dates):    \n",
    "    \"\"\"Get 3-week average sales for a site\"\"\"\n",
    "    print(f\" Getting 3-week average sales for {site_name}...\")\n",
    "    avg_start_row = None\n",
    "    product_name = None\n",
    "    avg_end_row = None\n",
    "    for offset in range(200):\n",
    "        row_idx = site_row + offset\n",
    "        if row_idx >= len(df):\n",
    "            break\n",
    "        \n",
    "        section_label = str(df.iloc[row_idx-1, 3]).strip() if pd.notna(df.iloc[row_idx-1, 3]) else \"\"\n",
    "        avg_col = str(df.iloc[row_idx, 4]).strip() if pd.notna(df.iloc[row_idx, 4]) else \"\"\n",
    "\n",
    "\n",
    "        if \"3 WK AVG\" in avg_col.upper():\n",
    "            avg_start_row = row_idx + 1\n",
    "            break\n",
    "    \n",
    "    if avg_start_row is None:\n",
    "        return []\n",
    "\n",
    "    # Find end of Avg Section\n",
    "    for offset in range(200):\n",
    "        row_idx = avg_start_row + offset\n",
    "        if row_idx >= len(df):\n",
    "            break\n",
    "        \n",
    "        section_label = str(df.iloc[row_idx, 3]).strip() if pd.notna(df.iloc[row_idx, 3]) else \"\"\n",
    "        \n",
    "        if any(keyword in section_label.upper() for keyword in ['ACTUAL']):\n",
    "            avg_end_row = row_idx\n",
    "            break\n",
    "    \n",
    "    if avg_end_row is None:\n",
    "        avg_end_row = avg_start_row + 100\n",
    "\n",
    "    records = []\n",
    "    products_found = {}\n",
    "\n",
    "    for row_idx in range(avg_start_row, avg_end_row):\n",
    "        if row_idx >= len(df):\n",
    "            break\n",
    "        \n",
    "        product_cell = df.iloc[row_idx-2, 4]\n",
    "        \n",
    "        if pd.notna(product_cell):\n",
    "            product = str(product_cell).strip()\n",
    "\n",
    "            if any(keyword in product for keyword in ['87', '88', '91', 'dsl', 'racing', 'red']):\n",
    "                if product not in products_found:\n",
    "                    products_found[product] = []\n",
    "                \n",
    "                products_found[product].append(row_idx)\n",
    "\n",
    "    for col_idx, date in all_dates:\n",
    "        for product, row_indices in products_found.items():\n",
    "            record = {\n",
    "                'Date': date.strftime('%Y-%m-%d'),\n",
    "                'Site': site_name,\n",
    "                'Product': product\n",
    "            }\n",
    "            for tank_num, row_idx in enumerate(row_indices, start=1):\n",
    "                value = df.iloc[row_idx-1, col_idx]\n",
    "                if pd.notna(value):\n",
    "                    try:\n",
    "                        clean_val = str(value).replace(',', '').strip()\n",
    "                        avg_val = float(clean_val) if clean_val else None\n",
    "                        record[f'Tank_{tank_num}_3_Week_Avg'] = avg_val\n",
    "                    except:\n",
    "                        record[f'Tank_{tank_num}_3_Week_Avg'] = None\n",
    "                else:\n",
    "                    record[f'Tank_{tank_num}_3_Week_Avg'] = None\n",
    "            \n",
    "            records.append(record)\n",
    "\n",
    "    return records\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "939890d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_2_month_avg(df, site_row, site_name, all_dates):    \n",
    "    \"\"\"Get 2-month average sales for a site\"\"\"\n",
    "    print(f\" Getting 2-month average sales for {site_name}...\")\n",
    "    avg_start_row = None\n",
    "    product_name = None\n",
    "    avg_end_row = None\n",
    "    for offset in range(200):\n",
    "        row_idx = site_row + offset\n",
    "        if row_idx >= len(df):\n",
    "            break\n",
    "        \n",
    "        section_label = str(df.iloc[row_idx-1, 3]).strip() if pd.notna(df.iloc[row_idx-1, 3]) else \"\"\n",
    "        avg_col = str(df.iloc[row_idx, 4]).strip() if pd.notna(df.iloc[row_idx, 4]) else \"\"\n",
    "\n",
    "\n",
    "        if \"2 MO AVG\" in avg_col.upper():\n",
    "            avg_start_row = row_idx + 1\n",
    "            break\n",
    "    \n",
    "    if avg_start_row is None:\n",
    "        return []\n",
    "\n",
    "    # Find end of Avg Section\n",
    "    for offset in range(200):\n",
    "        row_idx = avg_start_row + offset\n",
    "        if row_idx >= len(df):\n",
    "            break\n",
    "        \n",
    "        section_label = str(df.iloc[row_idx, 3]).strip() if pd.notna(df.iloc[row_idx, 3]) else \"\"\n",
    "        \n",
    "        if any(keyword in section_label.upper() for keyword in ['ACTUAL']):\n",
    "            avg_end_row = row_idx\n",
    "            break\n",
    "    \n",
    "    if avg_end_row is None:\n",
    "        avg_end_row = avg_start_row + 100\n",
    "\n",
    "    records = []\n",
    "    products_found = {}\n",
    "\n",
    "    for row_idx in range(avg_start_row, avg_end_row):\n",
    "        if row_idx >= len(df):\n",
    "            break\n",
    "        \n",
    "        product_cell = df.iloc[row_idx-3, 4]\n",
    "        \n",
    "        if pd.notna(product_cell):\n",
    "            product = str(product_cell).strip()\n",
    "            \n",
    "            if any(key in product for key in ['87', '88', '91', 'dsl', 'racing', 'red']):\n",
    "                if product not in products_found:\n",
    "                    products_found[product] = []\n",
    "                \n",
    "                products_found[product].append(row_idx)\n",
    "\n",
    "    for col_idx, date in all_dates:\n",
    "        for product, row_indices in products_found.items():\n",
    "            record = {\n",
    "                'Date': date.strftime('%Y-%m-%d'),\n",
    "                'Site': site_name,\n",
    "                'Product': product\n",
    "            }\n",
    "            for tank_num, row_idx in enumerate(row_indices, start=1):\n",
    "                value = df.iloc[row_idx-1, col_idx]\n",
    "                if pd.notna(value):\n",
    "                    try:\n",
    "                        clean_val = str(value).replace(',', '').strip()\n",
    "                        avg_val = float(clean_val) if clean_val else None\n",
    "                        record[f'Tank_{tank_num}_2_Month_Avg'] = avg_val\n",
    "                    except:\n",
    "                        record[f'Tank_{tank_num}_2_Month_Avg'] = None\n",
    "                else:\n",
    "                    record[f'Tank_{tank_num}_2_Month_Avg'] = None\n",
    "\n",
    "            records.append(record)\n",
    "\n",
    "    return records\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb255f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_site_loads(df, site_row, site_name, date_columns):\n",
    "    \"\"\"Extract loads (fuel deliveries) for a single site\"\"\"\n",
    "    print(f\"  Extracting LOADS for {site_name}...\")\n",
    "    \n",
    "    # First, find ULLAGE section\n",
    "    ullage_row = None\n",
    "    for offset in range(30):\n",
    "        row_idx = site_row + offset\n",
    "        if row_idx >= len(df):\n",
    "            break\n",
    "        \n",
    "        section_label = str(df.iloc[row_idx, 3]).strip() if pd.notna(df.iloc[row_idx, 3]) else \"\"\n",
    "        \n",
    "        if \"ULLAGE\" in section_label.upper():\n",
    "            ullage_row = row_idx\n",
    "            break\n",
    "    \n",
    "    if ullage_row is None:\n",
    "        return []\n",
    "    \n",
    "    # Now find LOADS section AFTER ullage\n",
    "    loads_start_row = None\n",
    "    loads_end_row = None\n",
    "    \n",
    "    for offset in range(1, 20):  # Start searching after ullage\n",
    "        row_idx = ullage_row + offset\n",
    "        if row_idx >= len(df):\n",
    "            break\n",
    "        \n",
    "        section_label = str(df.iloc[row_idx, 3]).strip() if pd.notna(df.iloc[row_idx, 3]) else \"\"\n",
    "        \n",
    "        if \"LOADS\" in section_label.upper():\n",
    "            loads_start_row = row_idx\n",
    "            break\n",
    "    \n",
    "    if loads_start_row is None:\n",
    "        return []\n",
    "    \n",
    "    # Find end of LOADS section\n",
    "    for offset in range(1, 15):\n",
    "        row_idx = loads_start_row + offset\n",
    "        if row_idx >= len(df):\n",
    "            break\n",
    "        \n",
    "        section_label = str(df.iloc[row_idx, 3]).strip() if pd.notna(df.iloc[row_idx, 3]) else \"\"\n",
    "        col1_label = str(df.iloc[row_idx, 1]).strip() if pd.notna(df.iloc[row_idx, 1]) else \"\"\n",
    "        \n",
    "        if any(keyword in section_label.upper() for keyword in ['SALES', 'CARRIER', 'NOTES']) or \\\n",
    "           any(keyword in col1_label.upper() for keyword in ['SALES', 'CARRIER']):\n",
    "            loads_end_row = row_idx\n",
    "            break\n",
    "    \n",
    "    if loads_end_row is None:\n",
    "        loads_end_row = loads_start_row + 10\n",
    "    \n",
    "    # Scan LOADS section - get product rows\n",
    "    records = []\n",
    "    products_found = {}\n",
    "    \n",
    "    for row_idx in range(loads_start_row, loads_end_row):\n",
    "        if row_idx >= len(df):\n",
    "            break\n",
    "        \n",
    "        product_cell = df.iloc[row_idx, 4]\n",
    "        \n",
    "        if pd.notna(product_cell):\n",
    "            product = str(product_cell).strip()\n",
    "            \n",
    "            # Get base product (87, 88, racing, red 91, dsl)\n",
    "            base_product = None\n",
    "            if any(keyword in product for keyword in ['87', '88', '91', 'dsl', 'racing', 'red']):\n",
    "                base_product = product\n",
    "            \n",
    "            # Capture all product rows (prefer total if exists, otherwise take the row)\n",
    "            if base_product:\n",
    "                is_total = \"total\" in product.lower()\n",
    "                # If we haven't seen this product yet, or this is a total row, store it\n",
    "                if base_product not in products_found or is_total:\n",
    "                    products_found[base_product] = row_idx\n",
    "    \n",
    "    # Extract loads for each date (only totals)\n",
    "    for col_idx, date in date_columns:\n",
    "        for product, row_idx in products_found.items():\n",
    "            value = df.iloc[row_idx, col_idx]\n",
    "            \n",
    "            if pd.notna(value):\n",
    "                try:\n",
    "                    clean_val = str(value).replace(',', '').strip()\n",
    "                    load_val = float(clean_val) if clean_val else None\n",
    "                    \n",
    "                    if load_val is not None:\n",
    "                        records.append({\n",
    "                            'Date': date.strftime('%Y-%m-%d'),\n",
    "                            'Site': site_name,\n",
    "                            'Product': product,\n",
    "                            'Load_Total': load_val\n",
    "                        })\n",
    "                except:\n",
    "                    pass\n",
    "    \n",
    "    return records\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "363c5d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_site_tank_sizes(df, site_row, site_name):\n",
    "    \"\"\"Extract tank sizes for a single site\"\"\"\n",
    "    print(f\"  Extracting TANK SIZES for {site_name}...\")\n",
    "    \n",
    "    # Find TANK SIZE label\n",
    "    tank_size_row = None\n",
    "    \n",
    "    for offset in range(40):\n",
    "        row_idx = site_row + offset\n",
    "        if row_idx >= len(df):\n",
    "            break\n",
    "        \n",
    "        label = str(df.iloc[row_idx, 1]).strip() if pd.notna(df.iloc[row_idx, 1]) else \"\"\n",
    "        \n",
    "        if \"TANK SIZE\" in label.upper():\n",
    "            tank_size_row = row_idx\n",
    "            break\n",
    "    \n",
    "    if tank_size_row is None:\n",
    "        return []\n",
    "    \n",
    "    # Extract tank sizes - first pass to collect all rows\n",
    "    records = []\n",
    "    products_data = {}  # {base_product: {'total': (row_idx, value), 'singles': [(row_idx, value), ...]}}\n",
    "    \n",
    "    for row_idx in range(tank_size_row + 1, tank_size_row + 20):\n",
    "        if row_idx >= len(df):\n",
    "            break\n",
    "        \n",
    "        col1_label = str(df.iloc[row_idx, 1]).strip() if pd.notna(df.iloc[row_idx, 1]) else \"\"\n",
    "        col3_label = str(df.iloc[row_idx, 3]).strip() if pd.notna(df.iloc[row_idx, 3]) else \"\"\n",
    "        \n",
    "        if \"SALES\" in col1_label.upper() or \"SALES\" in col3_label.upper():\n",
    "            break\n",
    "        \n",
    "        tank_size = df.iloc[row_idx, 1]\n",
    "        product_cell = df.iloc[row_idx, 4]\n",
    "        \n",
    "        if pd.notna(tank_size) and pd.notna(product_cell):\n",
    "            product = str(product_cell).strip()\n",
    "            \n",
    "            # Check if this product is relevant\n",
    "            if any(keyword in product for keyword in ['87', '88', '91', 'dsl', 'racing', 'red']):\n",
    "                is_total = \"total\" in product.lower()\n",
    "                # Get base product name (without \"total\")\n",
    "                base_product = product.lower().replace(\"total\", \"\").strip() if is_total else product\n",
    "                \n",
    "                try:\n",
    "                    clean_val = str(tank_size).replace(',', '').strip()\n",
    "                    size_val = float(clean_val) if clean_val else None\n",
    "                    \n",
    "                    if size_val and size_val > 0:\n",
    "                        if base_product not in products_data:\n",
    "                            products_data[base_product] = {'total': None, 'singles': []}\n",
    "                        \n",
    "                        if is_total:\n",
    "                            products_data[base_product]['total'] = (row_idx, size_val)\n",
    "                        else:\n",
    "                            products_data[base_product]['singles'].append((row_idx, size_val))\n",
    "                except:\n",
    "                    pass\n",
    "    \n",
    "    # Second pass: create records - use singles if they exist, otherwise use total\n",
    "    for base_product, data in products_data.items():\n",
    "        if data['singles']:  # If we have individual tanks, use those\n",
    "            for tank_num, (row_idx, size_val) in enumerate(data['singles'], start=1):\n",
    "                records.append({\n",
    "                    'Site': site_name,\n",
    "                    'Product': base_product,\n",
    "                    'Tank_Number': tank_num,\n",
    "                    'Tank_Size': size_val\n",
    "                })\n",
    "        elif data['total']:  # If we only have total, use that\n",
    "            row_idx, size_val = data['total']\n",
    "            records.append({\n",
    "                'Site': site_name,\n",
    "                'Product': base_product,\n",
    "                'Tank_Number': 1,\n",
    "                'Tank_Size': size_val\n",
    "            })\n",
    "    \n",
    "    return records\n",
    "\n",
    "    \"\"\"Extract tank sizes for a single site\"\"\"\n",
    "    print(f\"  Extracting TANK SIZES for {site_name}...\")\n",
    "    \n",
    "    # Find TANK SIZE label\n",
    "    tank_size_row = None\n",
    "    \n",
    "    for offset in range(40):\n",
    "        row_idx = site_row + offset\n",
    "        if row_idx >= len(df):\n",
    "            break\n",
    "        \n",
    "        label = str(df.iloc[row_idx, 1]).strip() if pd.notna(df.iloc[row_idx, 1]) else \"\"\n",
    "        \n",
    "        if \"TANK SIZE\" in label.upper():\n",
    "            tank_size_row = row_idx\n",
    "            break\n",
    "    \n",
    "    if tank_size_row is None:\n",
    "        return []\n",
    "    \n",
    "    # Extract tank sizes\n",
    "    records = []\n",
    "    products_found = {}\n",
    "    \n",
    "    for row_idx in range(tank_size_row + 1, tank_size_row + 20):\n",
    "        if row_idx >= len(df):\n",
    "            break\n",
    "        \n",
    "        col1_label = str(df.iloc[row_idx, 1]).strip() if pd.notna(df.iloc[row_idx, 1]) else \"\"\n",
    "        col3_label = str(df.iloc[row_idx, 3]).strip() if pd.notna(df.iloc[row_idx, 3]) else \"\"\n",
    "        \n",
    "        if \"SALES\" in col1_label.upper() or \"SALES\" in col3_label.upper():\n",
    "            break\n",
    "        \n",
    "        tank_size = df.iloc[row_idx, 1]\n",
    "        product_cell = df.iloc[row_idx, 4]\n",
    "        \n",
    "        if pd.notna(tank_size) and pd.notna(product_cell):\n",
    "            product = str(product_cell).strip()\n",
    "            \n",
    "            # Extract base product and strip \"total\" if present\n",
    "            base_product = None\n",
    "            if any(keyword in product for keyword in ['87', '88', '91', 'dsl', 'racing', 'red']):\n",
    "                # If \"total\" is in the product name, use the product without \"total\"\n",
    "                if \"total\" in product.lower():\n",
    "                    # Remove \"total\" and clean up extra spaces\n",
    "                    base_product = product.lower().replace(\"total\", \"\").strip()\n",
    "                else:\n",
    "                    base_product = product\n",
    "            \n",
    "            if base_product:\n",
    "                try:\n",
    "                    clean_val = str(tank_size).replace(',', '').strip()\n",
    "                    size_val = float(clean_val) if clean_val else None\n",
    "                    \n",
    "                    if size_val and size_val > 0:\n",
    "                        if base_product not in products_found:\n",
    "                            products_found[base_product] = []\n",
    "                        \n",
    "                        tank_num = len(products_found[base_product]) + 1\n",
    "                        products_found[base_product].append(size_val)\n",
    "                        \n",
    "                        records.append({\n",
    "                            'Site': site_name,\n",
    "                            'Product': base_product,\n",
    "                            'Tank_Number': tank_num,\n",
    "                            'Tank_Size': size_val\n",
    "                        })\n",
    "                except:\n",
    "                    pass\n",
    "    \n",
    "    return records\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ece32fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_site_inv_settings(df, site_row, site_name):\n",
    "    \"\"\"Extract inventory settings for a single site\"\"\"\n",
    "    print(f\"  Extracting INV SETTINGS for {site_name}...\")\n",
    "    \n",
    "    # Find INV SETTING label\n",
    "    inv_setting_row = None\n",
    "    \n",
    "    for offset in range(20):\n",
    "        row_idx = site_row + offset\n",
    "        if row_idx >= len(df):\n",
    "            break\n",
    "        \n",
    "        label = str(df.iloc[row_idx, 1]).strip() if pd.notna(df.iloc[row_idx, 1]) else \"\"\n",
    "        \n",
    "        if \"INV. SETTING\" in label.upper() or \"INV SETTING\" in label.upper():\n",
    "            inv_setting_row = row_idx\n",
    "            break\n",
    "    \n",
    "    if inv_setting_row is None:\n",
    "        return []\n",
    "    \n",
    "    # Extract inventory settings - first pass to collect all rows\n",
    "    records = []\n",
    "    products_data = {}  # {base_product: {'total': (row_idx, value), 'singles': [(row_idx, value), ...]}}\n",
    "    \n",
    "    for row_idx in range(inv_setting_row + 1, inv_setting_row + 20):\n",
    "        if row_idx >= len(df):\n",
    "            break\n",
    "        \n",
    "        col1_label = str(df.iloc[row_idx, 1]).strip() if pd.notna(df.iloc[row_idx, 1]) else \"\"\n",
    "        \n",
    "        if \"TANK SIZE\" in col1_label.upper():\n",
    "            break\n",
    "        \n",
    "        desired_level = df.iloc[row_idx, 1]\n",
    "        product_cell = df.iloc[row_idx, 4]\n",
    "        \n",
    "        if pd.notna(desired_level) and pd.notna(product_cell):\n",
    "            product = str(product_cell).strip()\n",
    "            \n",
    "            # Check if this product is relevant\n",
    "            if any(keyword in product for keyword in ['87', '88', '91', 'dsl', 'racing', 'red']):\n",
    "                is_total = \"total\" in product.lower()\n",
    "                # Get base product name (without \"total\")\n",
    "                base_product = product.lower().replace(\"total\", \"\").strip() if is_total else product\n",
    "                \n",
    "                try:\n",
    "                    clean_val = str(desired_level).replace(',', '').strip()\n",
    "                    level_val = float(clean_val) if clean_val else None\n",
    "                    \n",
    "                    if level_val and level_val > 0:\n",
    "                        if base_product not in products_data:\n",
    "                            products_data[base_product] = {'total': None, 'singles': []}\n",
    "                        \n",
    "                        if is_total:\n",
    "                            products_data[base_product]['total'] = (row_idx, level_val)\n",
    "                        else:\n",
    "                            products_data[base_product]['singles'].append((row_idx, level_val))\n",
    "                except:\n",
    "                    pass\n",
    "    \n",
    "    # Second pass: create records - use singles if they exist, otherwise use total\n",
    "    for base_product, data in products_data.items():\n",
    "        if data['singles']:  # If we have individual tanks, use those\n",
    "            for tank_num, (row_idx, level_val) in enumerate(data['singles'], start=1):\n",
    "                records.append({\n",
    "                    'Site': site_name,\n",
    "                    'Product': base_product,\n",
    "                    'Tank_Number': tank_num,\n",
    "                    'Desired_Level': level_val\n",
    "                })\n",
    "        elif data['total']:  # If we only have total, use that\n",
    "            row_idx, level_val = data['total']\n",
    "            records.append({\n",
    "                'Site': site_name,\n",
    "                'Product': base_product,\n",
    "                'Tank_Number': 1,\n",
    "                'Desired_Level': level_val\n",
    "            })\n",
    "    \n",
    "    return records\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f63579f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sites)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ccc57c0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting all dates...\n",
      "✓ Found 615 dates (up to today)\n",
      "  Date range: 2024-03-01 to 2025-11-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "615"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_dates = get_all_dates(df)\n",
    "len(all_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8a857431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Extracting READINGS for NEW Morongo Site #2...\n",
      "  Extracting INV SETTINGS for NEW Morongo Site #2...\n",
      " Getting 3-week average sales for NEW Morongo Site #2...\n",
      " Getting 2-month average sales for NEW Morongo Site #2...\n",
      "  Extracting TANK SIZES for NEW Morongo Site #2...\n"
     ]
    }
   ],
   "source": [
    "all_inv_settings = []\n",
    "all_readings = []\n",
    "all_three_week_avgs = []\n",
    "all_two_month_avgs = []\n",
    "all_tank_sizes = []\n",
    "for site_row, site_name in sites:\n",
    "    if site_name != \"NEW Morongo Site #2\":\n",
    "        continue\n",
    "    # print(f\"\\nProcessing site: {site_name})\")\n",
    "    readings = extract_site_readings(df, site_row, site_name, all_dates)\n",
    "    all_readings.extend(readings)\n",
    "    inv_settings = extract_site_inv_settings(df, site_row, site_name)\n",
    "    all_inv_settings.extend(inv_settings)\n",
    "    three_week_avgs = get_three_week_avg(df, site_row, site_name, all_dates)\n",
    "    all_three_week_avgs.extend(three_week_avgs)\n",
    "    two_month_avgs = get_2_month_avg(df, site_row, site_name, all_dates)\n",
    "    all_two_month_avgs.extend(two_month_avgs)\n",
    "    tank_sizes = extract_site_tank_sizes(df, site_row, site_name)\n",
    "    all_tank_sizes.extend(tank_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0be16fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_readings = pd.DataFrame(all_readings)\n",
    "df_inv_settings = pd.DataFrame(all_inv_settings)\n",
    "df_three_week_avgs = pd.DataFrame(all_three_week_avgs)\n",
    "df_two_month_avgs = pd.DataFrame(all_two_month_avgs)\n",
    "df_tank_sizes = pd.DataFrame(all_tank_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb39adca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Site",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Product",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Tank_Number",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Desired_Level",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "3a3f0c01-e8ee-4dae-8ca9-4c713382ceeb",
       "rows": [
        [
         "0",
         "NEW Morongo Site #2",
         "87",
         "1",
         "20000.0"
        ],
        [
         "1",
         "NEW Morongo Site #2",
         "87",
         "2",
         "20000.0"
        ],
        [
         "2",
         "NEW Morongo Site #2",
         "91",
         "1",
         "12000.0"
        ],
        [
         "3",
         "NEW Morongo Site #2",
         "dsl",
         "1",
         "21000.0"
        ],
        [
         "4",
         "NEW Morongo Site #2",
         "dsl",
         "2",
         "21000.0"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Site</th>\n",
       "      <th>Product</th>\n",
       "      <th>Tank_Number</th>\n",
       "      <th>Desired_Level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NEW Morongo Site #2</td>\n",
       "      <td>87</td>\n",
       "      <td>1</td>\n",
       "      <td>20000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NEW Morongo Site #2</td>\n",
       "      <td>87</td>\n",
       "      <td>2</td>\n",
       "      <td>20000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NEW Morongo Site #2</td>\n",
       "      <td>91</td>\n",
       "      <td>1</td>\n",
       "      <td>12000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NEW Morongo Site #2</td>\n",
       "      <td>dsl</td>\n",
       "      <td>1</td>\n",
       "      <td>21000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NEW Morongo Site #2</td>\n",
       "      <td>dsl</td>\n",
       "      <td>2</td>\n",
       "      <td>21000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Site Product  Tank_Number  Desired_Level\n",
       "0  NEW Morongo Site #2      87            1        20000.0\n",
       "1  NEW Morongo Site #2      87            2        20000.0\n",
       "2  NEW Morongo Site #2      91            1        12000.0\n",
       "3  NEW Morongo Site #2     dsl            1        21000.0\n",
       "4  NEW Morongo Site #2     dsl            2        21000.0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tank_sizes\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
