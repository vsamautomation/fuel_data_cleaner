{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e77bf5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "from io import StringIO\n",
    "from datetime import datetime\n",
    "import argparse\n",
    "import os\n",
    "from site_identifier import identify_sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1527bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "GOOGLE_SHEET_URL = \"https://docs.google.com/spreadsheets/d/e/2PACX-1vRpva-TXUaQR_6tJoXX2vnSN2ertC5GNxAgssqmXvIhqHBNrscDxSxtiSWbCiiHqAoSHb3SzXDQw_VX/pub?gid=1048590026&single=true&output=csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3b2c8f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data from Google Sheets...\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Fetch Google Sheets data\"\"\"\n",
    "print(\"Fetching data from Google Sheets...\")\n",
    "response = requests.get(GOOGLE_SHEET_URL, timeout=30)\n",
    "df = pd.read_csv(StringIO(response.text), header=None, low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "097e31f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identifying sites dynamically...\n",
      "Strategy: Finding 'INV. SETTING' labels and extracting site names\n",
      "\n",
      "  ✓ Row 4: OLD Morongo | Cabazon\n",
      "  ✓ Row 43: NEW Morongo Site #2\n",
      "  ✓ Row 93: Fort Independence\n",
      "  ✓ Row 127: Campo | Golden Acorn\n",
      "  ✓ Row 168: Bishop | Pauite Palace\n",
      "  ✓ Row 209: Bishop Pauite 2 Nobi\n",
      "  ✓ Row 248: Pechanga | Temecula\n",
      "  ✓ Row 283: Salton Sea | Red Earth\n",
      "  ✓ Row 350: Cahuilla | Anza\n",
      "  ✓ Row 385: La Jolla Trading Post\n",
      "  ✓ Row 420: Eagle Feather | Tule River\n",
      "  ✓ Row 455: Sycuan | El Cajon\n",
      "  ✓ Row 490: Rincon | Valley Center\n",
      "  ✓ Row 525: Santa Rosa Pit Stop\n",
      "  ✓ Row 560: Fort Mojave Smoke Shop\n",
      "  ✓ Row 599: Thalypo | Fort Mojave\n",
      "  ✓ Row 666: Pala\n",
      "  ✓ Row 701: Shivwits | Utah\n",
      "  ✓ Row 762: San Pasqual | Valley View\n",
      "  ✓ Row 905: Barona\n",
      "  ✓ Row 944: Kanosh | Pahvant Travel\n",
      "  ✓ Row 995: Santa Ysabel\n",
      "  ✓ Row 1029: Palms | Coachella\n",
      "  ✓ Row 1112: Kaibab | Red Cliffs\n",
      "  ✓ Row 1147: Viejas | Alpine\n",
      "  ✓ Row 1197: Chumash\n",
      "\n",
      "✓ Total sites identified: 26\n"
     ]
    }
   ],
   "source": [
    "sites = identify_sites(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "024480f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_dates(df, start_col=6):\n",
    "    \"\"\"Extract all date columns from the sheet (up to today only)\"\"\"\n",
    "    print(\"\\nExtracting all dates...\")\n",
    "    dates_row = df.iloc[0, start_col:]\n",
    "    \n",
    "    today = pd.Timestamp.now().normalize()  # Get today's date at midnight\n",
    "    \n",
    "    date_data = []\n",
    "    for col_idx, date_val in enumerate(dates_row, start=start_col):\n",
    "        if pd.notna(date_val):\n",
    "            try:\n",
    "                parsed = pd.to_datetime(str(date_val), format='%b-%d-%y', errors='coerce')\n",
    "                if parsed and parsed <= today:  # Only include dates up to today\n",
    "                    date_data.append((col_idx, parsed))\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "    print(f\"✓ Found {len(date_data)} dates (up to today)\")\n",
    "    if date_data:\n",
    "        print(f\"  Date range: {date_data[0][1].date()} to {date_data[-1][1].date()}\")\n",
    "    return date_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b03ca19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting all dates...\n",
      "✓ Found 610 dates (up to today)\n",
      "  Date range: 2024-03-01 to 2025-10-31\n"
     ]
    }
   ],
   "source": [
    "all_dates = get_all_dates(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee6acc08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_site_readings(df, site_row, site_name, date_columns):\n",
    "    \"\"\"Extract readings for a single site\"\"\"\n",
    "    print(f\"  Extracting READINGS for {site_name}...\")\n",
    "    \n",
    "    # Find READINGS section\n",
    "    reading_start_row = None\n",
    "    reading_end_row = None\n",
    "    \n",
    "    for offset in range(20):\n",
    "        row_idx = site_row + offset\n",
    "        if row_idx >= len(df):\n",
    "            break\n",
    "        \n",
    "        section_label = str(df.iloc[row_idx, 3]).strip() if pd.notna(df.iloc[row_idx, 3]) else \"\"\n",
    "        \n",
    "        if \"READINGS\" in section_label.upper():\n",
    "            reading_start_row = row_idx + 1\n",
    "            break\n",
    "    \n",
    "    if reading_start_row is None:\n",
    "        return []\n",
    "    \n",
    "    # Find end of READINGS section\n",
    "    for offset in range(15):\n",
    "        row_idx = reading_start_row + offset\n",
    "        if row_idx >= len(df):\n",
    "            break\n",
    "        \n",
    "        section_label = str(df.iloc[row_idx, 3]).strip() if pd.notna(df.iloc[row_idx, 3]) else \"\"\n",
    "        \n",
    "        if any(keyword in section_label.upper() for keyword in ['ULLAGE', 'LOADS', 'CARRIER', 'NOTES']):\n",
    "            reading_end_row = row_idx\n",
    "            break\n",
    "    \n",
    "    if reading_end_row is None:\n",
    "        reading_end_row = reading_start_row + 10\n",
    "    \n",
    "    # Scan READINGS section\n",
    "    records = []\n",
    "    products_found = {}\n",
    "    \n",
    "    for row_idx in range(reading_start_row, reading_end_row):\n",
    "        if row_idx >= len(df):\n",
    "            break\n",
    "        \n",
    "        product_cell = df.iloc[row_idx, 4]\n",
    "        \n",
    "        if pd.notna(product_cell):\n",
    "            product = str(product_cell).strip()\n",
    "            \n",
    "            for key in ['87', '88', '91', 'dsl', 'racing', 'red', 'total']:\n",
    "                if product.lower().startswith(key):\n",
    "                    if product not in products_found:\n",
    "                        products_found[product] = []\n",
    "                    products_found[product].append(row_idx)\n",
    "    \n",
    "    # Extract readings for each date\n",
    "    for col_idx, date in date_columns:\n",
    "        for product, row_indices in products_found.items():\n",
    "            record = {\n",
    "                'Date': date.strftime('%Y-%m-%d'),\n",
    "                'Site': site_name,\n",
    "                'Product': product\n",
    "            }\n",
    "            \n",
    "            for tank_num, row_idx in enumerate(row_indices, start=1):\n",
    "                value = df.iloc[row_idx, col_idx]\n",
    "                \n",
    "                if pd.notna(value):\n",
    "                    try:\n",
    "                        clean_val = str(value).replace(',', '').strip()\n",
    "                        numeric_val = float(clean_val) if clean_val else None\n",
    "                        record[f'Tank_{tank_num}_Reading'] = numeric_val\n",
    "                    except:\n",
    "                        record[f'Tank_{tank_num}_Reading'] = None\n",
    "                else:\n",
    "                    record[f'Tank_{tank_num}_Reading'] = None\n",
    "            \n",
    "            records.append(record)\n",
    "    \n",
    "    return records\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "85549bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_site_sales_actual(df, site_row, site_name, date_columns):\n",
    "    \"\"\"Extract actual sales for a single site\"\"\"\n",
    "    print(f\"  Extracting SALES (actual) for {site_name}...\")\n",
    "    \n",
    "    # Find SALES (actual) section\n",
    "    sales_start_row = None\n",
    "    \n",
    "    for offset in range(200):\n",
    "        row_idx = site_row + offset\n",
    "        if row_idx >= len(df):\n",
    "            break\n",
    "        \n",
    "        col1_label = str(df.iloc[row_idx, 1]).strip() if pd.notna(df.iloc[row_idx, 1]) else \"\"\n",
    "        col3_label = str(df.iloc[row_idx, 3]).strip() if pd.notna(df.iloc[row_idx, 3]) else \"\"\n",
    "        \n",
    "        # Look for SALES (actual) specifically, not SALES (projected)\n",
    "        if \"SALES\" in col1_label.upper() and \"ACTUAL\" in col1_label.upper():\n",
    "            sales_start_row = row_idx\n",
    "            break\n",
    "        elif \"ACTUAL\" in col3_label.upper() and \"SALES\" in col1_label.upper():\n",
    "            sales_start_row = row_idx\n",
    "            break\n",
    "    \n",
    "    if sales_start_row is None:\n",
    "        return []\n",
    "    \n",
    "    # Extract products in SALES (actual) section\n",
    "    records = []\n",
    "    products_found = {}\n",
    "    \n",
    "    for row_idx in range(sales_start_row, sales_start_row + 10):\n",
    "        if row_idx >= len(df):\n",
    "            break\n",
    "        \n",
    "        product_cell = df.iloc[row_idx, 4]\n",
    "        \n",
    "        if pd.notna(product_cell):\n",
    "            product = str(product_cell).strip()\n",
    "            if \"READING\" in product.upper():\n",
    "                # print(f\"    Reached end of products at row {row_idx}.\")\n",
    "                break\n",
    "            # Get base product (87, 88, racing, red, 91, dsl) - include totals\n",
    "            base_product = None\n",
    "            is_total = False\n",
    "            \n",
    "            if \"87\" in product:\n",
    "                base_product = product\n",
    "                is_total = \"total\" in product.lower()\n",
    "            elif \"88\" in product:\n",
    "                base_product = product\n",
    "                is_total = \"total\" in product.lower()\n",
    "            elif \"91\" in product:\n",
    "                base_product = product\n",
    "                is_total = \"total\" in product.lower()\n",
    "            elif \"dsl\" in product.lower():\n",
    "                base_product = product\n",
    "                is_total = \"total\" in product.lower()\n",
    "            elif \"racing\" in product.lower():\n",
    "                base_product = product\n",
    "                is_total = \"total\" in product.lower()\n",
    "            elif \"red\" in product.lower():\n",
    "                base_product = product\n",
    "                is_total = \"total\" in product.lower()\n",
    "\n",
    "\n",
    "            if base_product:\n",
    "                products_found[product] = {\n",
    "                    'row_idx': row_idx,\n",
    "                    'base_product': base_product,\n",
    "                    'is_total': is_total\n",
    "                }\n",
    "    \n",
    "    # Extract sales for each date\n",
    "    for col_idx, date in date_columns:\n",
    "        for product_key, product_info in products_found.items():\n",
    "            row_idx = product_info['row_idx']\n",
    "            value = df.iloc[row_idx, col_idx]\n",
    "            \n",
    "            if pd.notna(value):\n",
    "                try:\n",
    "                    clean_val = str(value).replace(',', '').strip()\n",
    "                    sales_val = float(clean_val) if clean_val else None\n",
    "                    \n",
    "                    if sales_val is not None:\n",
    "                        records.append({\n",
    "                            'Date': date.strftime('%Y-%m-%d'),\n",
    "                            'Site': site_name,\n",
    "                            'Product': product_info['base_product'],\n",
    "                            'Sales_Actual': sales_val,\n",
    "                            'Is_Total': product_info['is_total']\n",
    "                        })\n",
    "                except:\n",
    "                    pass\n",
    "    \n",
    "    return records\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ca356a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_three_week_avg(df, site_row, site_name, all_dates):    \n",
    "    \"\"\"Get 3-week average sales for a site\"\"\"\n",
    "    print(f\" Getting 3-week average sales for {site_name}...\")\n",
    "    avg_start_row = None\n",
    "    product_name = None\n",
    "    avg_end_row = None\n",
    "    for offset in range(200):\n",
    "        row_idx = site_row + offset\n",
    "        if row_idx >= len(df):\n",
    "            break\n",
    "        \n",
    "        section_label = str(df.iloc[row_idx-1, 3]).strip() if pd.notna(df.iloc[row_idx-1, 3]) else \"\"\n",
    "        avg_col = str(df.iloc[row_idx, 4]).strip() if pd.notna(df.iloc[row_idx, 4]) else \"\"\n",
    "\n",
    "\n",
    "        if \"3 WK AVG\" in avg_col.upper():\n",
    "            avg_start_row = row_idx + 1\n",
    "            break\n",
    "    \n",
    "    if avg_start_row is None:\n",
    "        return []\n",
    "\n",
    "    # Find end of Avg Section\n",
    "    for offset in range(200):\n",
    "        row_idx = avg_start_row + offset\n",
    "        if row_idx >= len(df):\n",
    "            break\n",
    "        \n",
    "        section_label = str(df.iloc[row_idx, 3]).strip() if pd.notna(df.iloc[row_idx, 3]) else \"\"\n",
    "        \n",
    "        if any(keyword in section_label.upper() for keyword in ['ACTUAL']):\n",
    "            avg_end_row = row_idx\n",
    "            break\n",
    "    \n",
    "    if avg_end_row is None:\n",
    "        avg_end_row = avg_start_row + 100\n",
    "\n",
    "    records = []\n",
    "    products_found = {}\n",
    "\n",
    "    for row_idx in range(avg_start_row, avg_end_row):\n",
    "        if row_idx >= len(df):\n",
    "            break\n",
    "        \n",
    "        product_cell = df.iloc[row_idx-2, 4]\n",
    "        \n",
    "        if pd.notna(product_cell):\n",
    "            product = str(product_cell).strip()\n",
    "            \n",
    "            if any(key in product for key in ['87', '88', '91', 'dsl', 'racing', 'red']):\n",
    "                if product not in products_found:\n",
    "                    products_found[product] = []\n",
    "                \n",
    "                products_found[product].append(row_idx)\n",
    "\n",
    "    for col_idx, date in all_dates:\n",
    "        for product, row_indices in products_found.items():\n",
    "            record = {\n",
    "                'Date': date.strftime('%Y-%m-%d'),\n",
    "                'Site': site_name,\n",
    "                'Product': product\n",
    "            }\n",
    "            for tank_num, row_idx in enumerate(row_indices, start=1):\n",
    "                value = df.iloc[row_idx-1, col_idx]\n",
    "                if pd.notna(value):\n",
    "                    try:\n",
    "                        clean_val = str(value).replace(',', '').strip()\n",
    "                        avg_val = float(clean_val) if clean_val else None\n",
    "                        record[f'Tank_{tank_num}_3_Week_Avg'] = avg_val\n",
    "                    except:\n",
    "                        record[f'Tank_{tank_num}_3_Week_Avg'] = None\n",
    "                else:\n",
    "                    record[f'Tank_{tank_num}_3_Week_Avg'] = None\n",
    "            \n",
    "            records.append(record)\n",
    "\n",
    "    return records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90708fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_2_month_avg(df, site_row, site_name, all_dates):    \n",
    "    \"\"\"Get 2-month average sales for a site\"\"\"\n",
    "    print(f\" Getting 2-month average sales for {site_name}...\")\n",
    "    avg_start_row = None\n",
    "    product_name = None\n",
    "    avg_end_row = None\n",
    "    for offset in range(200):\n",
    "        row_idx = site_row + offset\n",
    "        if row_idx >= len(df):\n",
    "            break\n",
    "        \n",
    "        section_label = str(df.iloc[row_idx-1, 3]).strip() if pd.notna(df.iloc[row_idx-1, 3]) else \"\"\n",
    "        avg_col = str(df.iloc[row_idx, 4]).strip() if pd.notna(df.iloc[row_idx, 4]) else \"\"\n",
    "\n",
    "\n",
    "        if \"2 MO AVG\" in avg_col.upper():\n",
    "            avg_start_row = row_idx + 1\n",
    "            break\n",
    "    \n",
    "    if avg_start_row is None:\n",
    "        return []\n",
    "\n",
    "    # Find end of Avg Section\n",
    "    for offset in range(200):\n",
    "        row_idx = avg_start_row + offset\n",
    "        if row_idx >= len(df):\n",
    "            break\n",
    "        \n",
    "        section_label = str(df.iloc[row_idx, 3]).strip() if pd.notna(df.iloc[row_idx, 3]) else \"\"\n",
    "        \n",
    "        if any(keyword in section_label.upper() for keyword in ['ACTUAL']):\n",
    "            avg_end_row = row_idx\n",
    "            break\n",
    "    \n",
    "    if avg_end_row is None:\n",
    "        avg_end_row = avg_start_row + 100\n",
    "\n",
    "    records = []\n",
    "    products_found = {}\n",
    "\n",
    "    for row_idx in range(avg_start_row, avg_end_row):\n",
    "        if row_idx >= len(df):\n",
    "            break\n",
    "        \n",
    "        product_cell = df.iloc[row_idx-3, 4]\n",
    "        \n",
    "        if pd.notna(product_cell):\n",
    "            product = str(product_cell).strip()\n",
    "            \n",
    "            if any(key in product for key in ['87', '88', '91', 'dsl', 'racing', 'red']):\n",
    "                if product not in products_found:\n",
    "                    products_found[product] = []\n",
    "                \n",
    "                products_found[product].append(row_idx)\n",
    "\n",
    "    for col_idx, date in all_dates:\n",
    "        for product, row_indices in products_found.items():\n",
    "            record = {\n",
    "                'Date': date.strftime('%Y-%m-%d'),\n",
    "                'Site': site_name,\n",
    "                'Product': product\n",
    "            }\n",
    "            for tank_num, row_idx in enumerate(row_indices, start=1):\n",
    "                value = df.iloc[row_idx-1, col_idx]\n",
    "                if pd.notna(value):\n",
    "                    try:\n",
    "                        clean_val = str(value).replace(',', '').strip()\n",
    "                        avg_val = float(clean_val) if clean_val else None\n",
    "                        record[f'Tank_{tank_num}_2_Month_Avg'] = avg_val\n",
    "                    except:\n",
    "                        record[f'Tank_{tank_num}_2_Month_Avg'] = None\n",
    "                else:\n",
    "                    record[f'Tank_{tank_num}_2_Month_Avg'] = None\n",
    "\n",
    "            records.append(record)\n",
    "\n",
    "    return records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea019e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "for site_row , site_name in sites:\n",
    "    print(f\"\\n{site_name}:\")\n",
    "\n",
    "    print(f\"  Extracting SALES (actual) for {site_name}...\")\n",
    "    sales_start_row = None\n",
    "\n",
    "    for offset in range(40):\n",
    "        row_idx = site_row + offset\n",
    "        if row_idx >= len(df):\n",
    "            break\n",
    "        \n",
    "        col1_label = str(df.iloc[row_idx, 1]).strip() if pd.notna(df.iloc[row_idx, 1]) else \"\"\n",
    "        col3_label = str(df.iloc[row_idx, 3]).strip() if pd.notna(df.iloc[row_idx, 3]) else \"\"\n",
    "\n",
    "        if \"SALES\" in col1_label.upper() and \"ACTUAL\" in col3_label.upper():\n",
    "            sales_start_row = row_idx\n",
    "            break\n",
    "        elif \"ACTUAL\" in col3_label.upper() and 'SALES' in col1_label.upper():\n",
    "            sales_start_row = row_idx\n",
    "            break\n",
    "    print(f\"    Found SALES (actual) row at index {sales_start_row}\")\n",
    "\n",
    "    if sales_start_row is None:\n",
    "        print(f\"    ⚠️ SALES (actual) row not found for {site_name}, skipping...\")\n",
    "        break\n",
    "    records = []\n",
    "    products_found = {}\n",
    "\n",
    "    for row_idx in range(sales_start_row, sales_start_row+10):\n",
    "        if row_idx >= len(df):\n",
    "            break\n",
    "\n",
    "        product_cell = df.iloc[row_idx, 4]\n",
    "        # print(f\"    Checking row {row_idx}, product cell: {product_cell}\")\n",
    "\n",
    "        if pd.notna(product_cell):\n",
    "            product = str(product_cell).strip()\n",
    "            # print(f\"    Found product: {product}\")\n",
    "            if \"READING\" in product.upper():\n",
    "                # print(f\"    Reached end of products at row {row_idx}.\")\n",
    "                break\n",
    "            base_product = None\n",
    "            is_total = False\n",
    "\n",
    "            if \"87\" in product:\n",
    "                base_product = product\n",
    "                is_total = \"total\" in product.upper()\n",
    "            elif \"91\" in product:\n",
    "                base_product = product\n",
    "                is_total = \"total\" in product.upper()\n",
    "            elif \"dsl\" in product.lower():\n",
    "                base_product = product\n",
    "                is_total = \"total\" in product.lower()\n",
    "            \n",
    "            if base_product:\n",
    "                products_found[product] = {\n",
    "                    'row_idx': row_idx,\n",
    "                    'base_product': base_product,\n",
    "                    'is_total': is_total\n",
    "                }\n",
    "\n",
    "    print(f\"    Products found so far: {products_found}\")\n",
    "\n",
    "    for col_idx, date in all_dates:\n",
    "        for _, product_info in products_found.items():\n",
    "            row_idx = product_info['row_idx']\n",
    "            value = df.iloc[row_idx, col_idx]\n",
    "\n",
    "            print(f\"      Date: {date.date()}, Product: {product_info['base_product']}, Value: {value}, Col: {col_idx}, Row: {row_idx}\")\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fa5069d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Getting 3-week average sales for Salton Sea | Red Earth...\n",
      "   Found 3 WK AVG at row 313\n"
     ]
    }
   ],
   "source": [
    "for site_row, site_name in sites:\n",
    "    if site_name != \"Salton Sea | Red Earth\":\n",
    "        continue\n",
    "        \"\"\"Get 3-week average sales for a site\"\"\"\n",
    "    print(f\" Getting 3-week average sales for {site_name}...\")\n",
    "    avg_start_row = None\n",
    "    product_name = None\n",
    "    avg_end_row = None\n",
    "    for offset in range(200):\n",
    "        row_idx = site_row + offset\n",
    "        if row_idx >= len(df):\n",
    "            break\n",
    "        \n",
    "        section_label = str(df.iloc[row_idx-1, 3]).strip() if pd.notna(df.iloc[row_idx-1, 3]) else \"\"\n",
    "        avg_col = str(df.iloc[row_idx, 4]).strip() if pd.notna(df.iloc[row_idx, 4]) else \"\"\n",
    "\n",
    "\n",
    "        if \"3 WK AVG\" in avg_col.upper():\n",
    "            avg_start_row = row_idx + 1\n",
    "            print(f\"   Found 3 WK AVG at row {avg_start_row}\")\n",
    "            break\n",
    "    \n",
    "    if avg_start_row is None:\n",
    "        print(\"   3 WK AVG section not found, skipping...\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a95211f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Getting 3-week average sales for OLD Morongo | Cabazon...\n",
      "    ✓ 1830 3-week average records\n",
      " Getting 2-month average sales for OLD Morongo | Cabazon...\n",
      " Getting 3-week average sales for NEW Morongo Site #2...\n",
      "    ✓ 1830 3-week average records\n",
      " Getting 2-month average sales for NEW Morongo Site #2...\n",
      " Getting 3-week average sales for Fort Independence...\n",
      "    ✓ 1830 3-week average records\n",
      " Getting 2-month average sales for Fort Independence...\n",
      " Getting 3-week average sales for Campo | Golden Acorn...\n",
      "    ✓ 1830 3-week average records\n",
      " Getting 2-month average sales for Campo | Golden Acorn...\n",
      " Getting 3-week average sales for Bishop | Pauite Palace...\n",
      "    ✓ 1830 3-week average records\n",
      " Getting 2-month average sales for Bishop | Pauite Palace...\n",
      " Getting 3-week average sales for Bishop Pauite 2 Nobi...\n",
      "    ✓ 1830 3-week average records\n",
      " Getting 2-month average sales for Bishop Pauite 2 Nobi...\n",
      " Getting 3-week average sales for Pechanga | Temecula...\n",
      "    ✓ 1830 3-week average records\n",
      " Getting 2-month average sales for Pechanga | Temecula...\n",
      " Getting 3-week average sales for Salton Sea | Red Earth...\n",
      "    ✓ 4270 3-week average records\n",
      " Getting 2-month average sales for Salton Sea | Red Earth...\n",
      " Getting 3-week average sales for Cahuilla | Anza...\n",
      "    ✓ 1830 3-week average records\n",
      " Getting 2-month average sales for Cahuilla | Anza...\n",
      " Getting 3-week average sales for La Jolla Trading Post...\n",
      "    ✓ 1830 3-week average records\n",
      " Getting 2-month average sales for La Jolla Trading Post...\n",
      " Getting 3-week average sales for Eagle Feather | Tule River...\n",
      "    ✓ 1830 3-week average records\n",
      " Getting 2-month average sales for Eagle Feather | Tule River...\n",
      " Getting 3-week average sales for Sycuan | El Cajon...\n",
      "    ✓ 1830 3-week average records\n",
      " Getting 2-month average sales for Sycuan | El Cajon...\n",
      " Getting 3-week average sales for Rincon | Valley Center...\n",
      "    ✓ 1830 3-week average records\n",
      " Getting 2-month average sales for Rincon | Valley Center...\n",
      " Getting 3-week average sales for Santa Rosa Pit Stop...\n",
      "    ✓ 1830 3-week average records\n",
      " Getting 2-month average sales for Santa Rosa Pit Stop...\n",
      " Getting 3-week average sales for Fort Mojave Smoke Shop...\n",
      "    ✓ 1830 3-week average records\n",
      " Getting 2-month average sales for Fort Mojave Smoke Shop...\n",
      " Getting 3-week average sales for Thalypo | Fort Mojave...\n",
      "    ✓ 3660 3-week average records\n",
      " Getting 2-month average sales for Thalypo | Fort Mojave...\n",
      " Getting 3-week average sales for Pala...\n",
      "    ✓ 1830 3-week average records\n",
      " Getting 2-month average sales for Pala...\n",
      " Getting 3-week average sales for Shivwits | Utah...\n",
      "    ✓ 3050 3-week average records\n",
      " Getting 2-month average sales for Shivwits | Utah...\n",
      " Getting 3-week average sales for San Pasqual | Valley View...\n",
      "    ✓ 1830 3-week average records\n",
      " Getting 2-month average sales for San Pasqual | Valley View...\n",
      " Getting 3-week average sales for Barona...\n",
      "    ✓ 1830 3-week average records\n",
      " Getting 2-month average sales for Barona...\n",
      " Getting 3-week average sales for Kanosh | Pahvant Travel...\n",
      "    ✓ 2440 3-week average records\n",
      " Getting 2-month average sales for Kanosh | Pahvant Travel...\n",
      " Getting 3-week average sales for Santa Ysabel...\n",
      "    ✓ 1830 3-week average records\n",
      " Getting 2-month average sales for Santa Ysabel...\n",
      " Getting 3-week average sales for Palms | Coachella...\n",
      "    ✓ 4880 3-week average records\n",
      " Getting 2-month average sales for Palms | Coachella...\n",
      " Getting 3-week average sales for Kaibab | Red Cliffs...\n",
      "    ✓ 1830 3-week average records\n",
      " Getting 2-month average sales for Kaibab | Red Cliffs...\n",
      " Getting 3-week average sales for Viejas | Alpine...\n",
      "    ✓ 2440 3-week average records\n",
      " Getting 2-month average sales for Viejas | Alpine...\n",
      " Getting 3-week average sales for Chumash...\n",
      "    ✓ 1830 3-week average records\n",
      " Getting 2-month average sales for Chumash...\n"
     ]
    }
   ],
   "source": [
    "all_readings = []\n",
    "all_loads = []\n",
    "all_tank_sizes = []\n",
    "all_inv_settings = []\n",
    "all_sales_actual = []\n",
    "all_three_week_avg = []\n",
    "all_2_month_avg = []\n",
    "for site_row, site_name in sites:\n",
    "    # readings = extract_site_readings(df, site_row, site_name, all_dates)\n",
    "    # all_readings.extend(readings)\n",
    "    # print(f\"    ✓ {len(readings)} reading records\")\n",
    "    # # Extract sales actual\n",
    "    # sales_actual = extract_site_sales_actual(df, site_row, site_name, all_dates)\n",
    "    # all_sales_actual.extend(sales_actual)\n",
    "    # print(f\"    ✓ {len(sales_actual)} sales actual records\")\n",
    "\n",
    "    three_week_avg = get_three_week_avg(df, site_row, site_name, all_dates)\n",
    "    all_three_week_avg.extend(three_week_avg)\n",
    "    print(f\"    ✓ {len(three_week_avg)} 3-week average records\")\n",
    "\n",
    "    two_month_avg = get_2_month_avg(df, site_row, site_name, all_dates)\n",
    "    all_2_month_avg.extend(two_month_avg)\n",
    "\n",
    "# df_readings = pd.DataFrame(all_readings)\n",
    "# df_sales_actual = pd.DataFrame(all_sales_actual)\n",
    "df_three_week_avg = pd.DataFrame(all_three_week_avg)\n",
    "df_2_month_avg = pd.DataFrame(all_2_month_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "991a8194",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Date",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Site",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Product",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Tank_1_3_Week_Avg",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Tank_2_3_Week_Avg",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "58272904-9a40-4a75-a977-166dd198ba3c",
       "rows": [
        [
         "0",
         "2024-03-01",
         "OLD Morongo | Cabazon",
         "87",
         "29734.0",
         null
        ],
        [
         "1",
         "2024-03-01",
         "OLD Morongo | Cabazon",
         "91",
         "5899.0",
         null
        ],
        [
         "2",
         "2024-03-01",
         "OLD Morongo | Cabazon",
         "dsl",
         "4792.0",
         null
        ],
        [
         "3",
         "2024-03-02",
         "OLD Morongo | Cabazon",
         "87",
         "32464.0",
         null
        ],
        [
         "4",
         "2024-03-02",
         "OLD Morongo | Cabazon",
         "91",
         "7807.0",
         null
        ],
        [
         "5",
         "2024-03-02",
         "OLD Morongo | Cabazon",
         "dsl",
         "4413.0",
         null
        ],
        [
         "6",
         "2024-03-03",
         "OLD Morongo | Cabazon",
         "87",
         "29180.0",
         null
        ],
        [
         "7",
         "2024-03-03",
         "OLD Morongo | Cabazon",
         "91",
         "6792.0",
         null
        ],
        [
         "8",
         "2024-03-03",
         "OLD Morongo | Cabazon",
         "dsl",
         "3849.0",
         null
        ],
        [
         "9",
         "2024-03-04",
         "OLD Morongo | Cabazon",
         "87",
         "28912.0",
         null
        ],
        [
         "10",
         "2024-03-04",
         "OLD Morongo | Cabazon",
         "91",
         "4523.0",
         null
        ],
        [
         "11",
         "2024-03-04",
         "OLD Morongo | Cabazon",
         "dsl",
         "3563.0",
         null
        ],
        [
         "12",
         "2024-03-05",
         "OLD Morongo | Cabazon",
         "87",
         "23307.0",
         null
        ],
        [
         "13",
         "2024-03-05",
         "OLD Morongo | Cabazon",
         "91",
         "4467.0",
         null
        ],
        [
         "14",
         "2024-03-05",
         "OLD Morongo | Cabazon",
         "dsl",
         "3453.0",
         null
        ],
        [
         "15",
         "2024-03-06",
         "OLD Morongo | Cabazon",
         "87",
         "24308.0",
         null
        ],
        [
         "16",
         "2024-03-06",
         "OLD Morongo | Cabazon",
         "91",
         "3761.0",
         null
        ],
        [
         "17",
         "2024-03-06",
         "OLD Morongo | Cabazon",
         "dsl",
         "4176.0",
         null
        ],
        [
         "18",
         "2024-03-07",
         "OLD Morongo | Cabazon",
         "87",
         "24848.0",
         null
        ],
        [
         "19",
         "2024-03-07",
         "OLD Morongo | Cabazon",
         "91",
         "4814.0",
         null
        ],
        [
         "20",
         "2024-03-07",
         "OLD Morongo | Cabazon",
         "dsl",
         "4458.0",
         null
        ],
        [
         "21",
         "2024-03-08",
         "OLD Morongo | Cabazon",
         "87",
         "31189.0",
         null
        ],
        [
         "22",
         "2024-03-08",
         "OLD Morongo | Cabazon",
         "91",
         "6028.0",
         null
        ],
        [
         "23",
         "2024-03-08",
         "OLD Morongo | Cabazon",
         "dsl",
         "4679.0",
         null
        ],
        [
         "24",
         "2024-03-09",
         "OLD Morongo | Cabazon",
         "87",
         "29525.0",
         null
        ],
        [
         "25",
         "2024-03-09",
         "OLD Morongo | Cabazon",
         "91",
         "7093.0",
         null
        ],
        [
         "26",
         "2024-03-09",
         "OLD Morongo | Cabazon",
         "dsl",
         "3897.0",
         null
        ],
        [
         "27",
         "2024-03-10",
         "OLD Morongo | Cabazon",
         "87",
         "30599.0",
         null
        ],
        [
         "28",
         "2024-03-10",
         "OLD Morongo | Cabazon",
         "91",
         "7088.0",
         null
        ],
        [
         "29",
         "2024-03-10",
         "OLD Morongo | Cabazon",
         "dsl",
         "4257.0",
         null
        ],
        [
         "30",
         "2024-03-11",
         "OLD Morongo | Cabazon",
         "87",
         "27542.0",
         null
        ],
        [
         "31",
         "2024-03-11",
         "OLD Morongo | Cabazon",
         "91",
         "4632.0",
         null
        ],
        [
         "32",
         "2024-03-11",
         "OLD Morongo | Cabazon",
         "dsl",
         "4044.0",
         null
        ],
        [
         "33",
         "2024-03-12",
         "OLD Morongo | Cabazon",
         "87",
         "24124.0",
         null
        ],
        [
         "34",
         "2024-03-12",
         "OLD Morongo | Cabazon",
         "91",
         "4505.0",
         null
        ],
        [
         "35",
         "2024-03-12",
         "OLD Morongo | Cabazon",
         "dsl",
         "3906.0",
         null
        ],
        [
         "36",
         "2024-03-13",
         "OLD Morongo | Cabazon",
         "87",
         "24072.0",
         null
        ],
        [
         "37",
         "2024-03-13",
         "OLD Morongo | Cabazon",
         "91",
         "3951.0",
         null
        ],
        [
         "38",
         "2024-03-13",
         "OLD Morongo | Cabazon",
         "dsl",
         "4011.0",
         null
        ],
        [
         "39",
         "2024-03-14",
         "OLD Morongo | Cabazon",
         "87",
         "26215.0",
         null
        ],
        [
         "40",
         "2024-03-14",
         "OLD Morongo | Cabazon",
         "91",
         "4761.0",
         null
        ],
        [
         "41",
         "2024-03-14",
         "OLD Morongo | Cabazon",
         "dsl",
         "4676.0",
         null
        ],
        [
         "42",
         "2024-03-15",
         "OLD Morongo | Cabazon",
         "87",
         "30990.0",
         null
        ],
        [
         "43",
         "2024-03-15",
         "OLD Morongo | Cabazon",
         "91",
         "6167.0",
         null
        ],
        [
         "44",
         "2024-03-15",
         "OLD Morongo | Cabazon",
         "dsl",
         "4538.0",
         null
        ],
        [
         "45",
         "2024-03-16",
         "OLD Morongo | Cabazon",
         "87",
         "27143.0",
         null
        ],
        [
         "46",
         "2024-03-16",
         "OLD Morongo | Cabazon",
         "91",
         "6695.0",
         null
        ],
        [
         "47",
         "2024-03-16",
         "OLD Morongo | Cabazon",
         "dsl",
         "4010.0",
         null
        ],
        [
         "48",
         "2024-03-17",
         "OLD Morongo | Cabazon",
         "87",
         "29820.0",
         null
        ],
        [
         "49",
         "2024-03-17",
         "OLD Morongo | Cabazon",
         "91",
         "6892.0",
         null
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 57340
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Site</th>\n",
       "      <th>Product</th>\n",
       "      <th>Tank_1_3_Week_Avg</th>\n",
       "      <th>Tank_2_3_Week_Avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-03-01</td>\n",
       "      <td>OLD Morongo | Cabazon</td>\n",
       "      <td>87</td>\n",
       "      <td>29734.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-03-01</td>\n",
       "      <td>OLD Morongo | Cabazon</td>\n",
       "      <td>91</td>\n",
       "      <td>5899.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-03-01</td>\n",
       "      <td>OLD Morongo | Cabazon</td>\n",
       "      <td>dsl</td>\n",
       "      <td>4792.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-03-02</td>\n",
       "      <td>OLD Morongo | Cabazon</td>\n",
       "      <td>87</td>\n",
       "      <td>32464.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-03-02</td>\n",
       "      <td>OLD Morongo | Cabazon</td>\n",
       "      <td>91</td>\n",
       "      <td>7807.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57335</th>\n",
       "      <td>2025-10-30</td>\n",
       "      <td>Chumash</td>\n",
       "      <td>91</td>\n",
       "      <td>299.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57336</th>\n",
       "      <td>2025-10-30</td>\n",
       "      <td>Chumash</td>\n",
       "      <td>dsl</td>\n",
       "      <td>1276.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57337</th>\n",
       "      <td>2025-10-31</td>\n",
       "      <td>Chumash</td>\n",
       "      <td>87</td>\n",
       "      <td>4876.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57338</th>\n",
       "      <td>2025-10-31</td>\n",
       "      <td>Chumash</td>\n",
       "      <td>91</td>\n",
       "      <td>1877.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57339</th>\n",
       "      <td>2025-10-31</td>\n",
       "      <td>Chumash</td>\n",
       "      <td>dsl</td>\n",
       "      <td>-273.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>57340 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Date                   Site Product  Tank_1_3_Week_Avg  \\\n",
       "0      2024-03-01  OLD Morongo | Cabazon      87            29734.0   \n",
       "1      2024-03-01  OLD Morongo | Cabazon      91             5899.0   \n",
       "2      2024-03-01  OLD Morongo | Cabazon     dsl             4792.0   \n",
       "3      2024-03-02  OLD Morongo | Cabazon      87            32464.0   \n",
       "4      2024-03-02  OLD Morongo | Cabazon      91             7807.0   \n",
       "...           ...                    ...     ...                ...   \n",
       "57335  2025-10-30                Chumash      91              299.0   \n",
       "57336  2025-10-30                Chumash     dsl             1276.0   \n",
       "57337  2025-10-31                Chumash      87             4876.0   \n",
       "57338  2025-10-31                Chumash      91             1877.0   \n",
       "57339  2025-10-31                Chumash     dsl             -273.0   \n",
       "\n",
       "       Tank_2_3_Week_Avg  \n",
       "0                    NaN  \n",
       "1                    NaN  \n",
       "2                    NaN  \n",
       "3                    NaN  \n",
       "4                    NaN  \n",
       "...                  ...  \n",
       "57335                NaN  \n",
       "57336                NaN  \n",
       "57337                NaN  \n",
       "57338                NaN  \n",
       "57339                NaN  \n",
       "\n",
       "[57340 rows x 5 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_three_week_avg"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
